{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto Prático 4\n",
    "\n",
    "**Universidade do Estado do Amazonas**  \n",
    "**Escola Superior de Tecnologia**  \n",
    "**Professora:** Elloá B. Guedes  \n",
    "**Alunos:** Juliany Raiol, Raí Soledade, Richardson Souza  \n",
    "**Disciplina:** Redes Neurais Artificiais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado de Máquina com tarefa de classificação aplicado no dataset  de variedades de trigo\n",
    "\n",
    "### Introdução\n",
    "\n",
    "Três variedades de trigo (Kama, Rosa e Canadian) possuem sementes muito parecidas,\n",
    "entretanto diferentes. Um grupo de pesquisadores poloneses coletou 70 amostras de cada\n",
    "tipo e, usando uma técnica particular de raio-X, coletou medidas geométricas destas\n",
    "sementes, a citar: área, perímetro, compactude, comprimento, largura, coeficiente de\n",
    "assimetria e comprimento do sulco da semente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos utilizados no projeto\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Area\", \"Perimeter\", \"Compactness\", \"Length\", \"Width\", \"Asymmetry\", \"Groove\", \"Seed\"]\n",
    "\n",
    "df = pd.read_csv('../../data/seeds_dataset.txt', delim_whitespace=True, names = names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Seed', axis=1)\n",
    "y = df['Seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate  = [0.01, 0.05]\n",
    "epoch = 50\n",
    "a     = [0.5, 2, 3]\n",
    "\n",
    "\n",
    "n_network  = 2\n",
    "max_iter   = [1000, 2000,  2500]\n",
    "neuron_out = np.arange(1, 15)\n",
    "neuron_ini = np.arange(1, 15)\n",
    "solver     = ['lbfgs', 'sgd', 'adam']\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prediction = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianyraiol/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/julianyraiol/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/julianyraiol/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/julianyraiol/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_network):\n",
    "    ai  = random.choice(a)\n",
    "    ni  = random.choice(neuron_ini)\n",
    "    no  = random.choice(neuron_out)\n",
    "    \n",
    "    nh  = ai*np.sqrt((ni*no))\n",
    "    activation = random.choice(activation_functions)\n",
    "    parameters = dict([\n",
    "                    ('max_iter', max_iter),\n",
    "                    ('hidden_layer_sizes', (no,)),\n",
    "                    ('learning_rate_init', rate),\n",
    "                    ('solver', solver),\n",
    "                    ('activation', activation_functions)\n",
    "                ])\n",
    "\n",
    "    clf = GridSearchCV(MLPClassifier(), parameters, cv = 3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediction = clf.predict(X_test)\n",
    "    f1score    = f1_score(y_test, prediction, average = 'weighted')\n",
    "    \n",
    "    network = dict([\n",
    "        ('f1_score', f1score),\n",
    "        ('prediction', prediction),\n",
    "        ('estimator', clf.best_estimator_),\n",
    "        ('params', clf.best_params_)\n",
    "    ])\n",
    "    \n",
    "    list_prediction.append(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Rede 0\n",
      "f1_score ===== 0.9209188744072466 \n",
      "\n",
      "prediction ===== [2 1 2 2 1 1 3 2 3 2 2 2 1 2 3 2 2 2 2 3 2 1 2 1 3 1 1 3 1 1 2 2 1 3 1 3 3\n",
      " 3 1 1 1 2 3 3 3 1 3 3 1 2 3 3 1 1 2 1 3 3 3 2 2 2 1] \n",
      "\n",
      "estimator ===== MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=11, learning_rate='constant',\n",
      "       learning_rate_init=0.01, max_iter=2500, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) \n",
      "\n",
      "params ===== {'activation': 'identity', 'hidden_layer_sizes': 11, 'learning_rate_init': 0.01, 'max_iter': 2500, 'solver': 'lbfgs'} \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Rede 1\n",
      "f1_score ===== 0.9065003779289493 \n",
      "\n",
      "prediction ===== [1 1 2 2 1 1 3 2 3 2 2 2 1 2 1 2 2 2 2 3 2 1 2 1 3 1 1 3 1 1 2 2 1 3 1 3 1\n",
      " 3 1 1 1 2 3 3 3 1 3 3 1 2 3 3 1 3 2 1 3 3 3 2 2 2 2] \n",
      "\n",
      "estimator ===== MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=5, learning_rate='constant',\n",
      "       learning_rate_init=0.01, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) \n",
      "\n",
      "params ===== {'activation': 'relu', 'hidden_layer_sizes': 5, 'learning_rate_init': 0.01, 'max_iter': 2000, 'solver': 'lbfgs'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for dictnet in list_prediction:\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    print(\"Rede\", i)\n",
    "    for key, value in dictnet.items():\n",
    "        print(key, \"=====\", value, \"\\n\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
