{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto Prático 4\n",
    "\n",
    "**Universidade do Estado do Amazonas**  \n",
    "**Escola Superior de Tecnologia**  \n",
    "**Professora:** Elloá B. Guedes  \n",
    "**Alunos:** Juliany Raiol, Raí Soledade, Richardson Souza  \n",
    "**Disciplina:** Redes Neurais Artificiais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado de Máquina com tarefa de classificação aplicado no dataset  de variedades de trigo\n",
    "\n",
    "### Introdução\n",
    "\n",
    "Três variedades de trigo (Kama, Rosa e Canadian) possuem sementes muito parecidas,\n",
    "entretanto diferentes. Um grupo de pesquisadores poloneses coletou 70 amostras de cada\n",
    "tipo e, usando uma técnica particular de raio-X, coletou medidas geométricas destas\n",
    "sementes, a citar: área, perímetro, compactude, comprimento, largura, coeficiente de\n",
    "assimetria e comprimento do sulco da semente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos utilizados no projeto\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Area\", \"Perimeter\", \"Compactness\", \"Length\", \"Width\", \"Asymmetry\", \"Groove\", \"Seed\"]\n",
    "\n",
    "df = pd.read_csv('../../data/seeds_dataset.txt', delim_whitespace=True, names = names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = atributos preditores, y = atributo alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Seed', axis=1)\n",
    "y = df['Seed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição dos parâmetros de taxa de aprendizado, neurônios na camada de entrada e saída, funções de ativação e o alfa da regra da pirâmide geométrica utilizada para calcular a quantidade de neurônios nas camadas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate  = [0.01, 0.05]\n",
    "alpha = [0.5, 2, 3]\n",
    "\n",
    "neuron_out = 2\n",
    "neuron_ini = 7\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo da quantidade de neurônios nas camadas ocultas utilizando a regra da pirâmide geométrica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de neurônios nas camadas ocultas a serem testadas respectivamente:  [1, 7, 11]\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "for a in alpha:\n",
    "    n.append(int( a * np.sqrt((neuron_ini*neuron_out))))\n",
    "print(\"Quantidade de neurônios nas camadas ocultas a serem testadas respectivamente: \", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetro que define uma série de combinações de neurônios distribuídos em 1 ou 2 camadas, de acordo com a quantidade de neurônios calculada anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = [(1,), (7,),(1,6),(2,5),(3,4), (11,),(1,10),(2,9),(3,8),(4,7),(5,6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição dos parâmetros para inicialização dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict([\n",
    "                ('hidden_layer_sizes', hidden_layer),\n",
    "                ('learning_rate_init', rate),\n",
    "                ('activation', activation_functions)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento das redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'hidden_layer_sizes': [(1,), (7,), (1, 6), (2, 5), (3, 4), (11,), (1, 10), (2, 9), (3, 8), (4, 7), (5, 6)], 'learning_rate_init': [0.01, 0.05], 'activation': ['identity', 'logistic', 'tanh', 'relu']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(MLPClassifier(solver='lbfgs'), parameters, iid=True, cv = 3, return_train_score=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listagem de todas as redes neurais geradas pelo GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046853</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.065948</td>\n",
       "      <td>33</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.921986</td>\n",
       "      <td>0.885703</td>\n",
       "      <td>0.028977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055086</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>25</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.892846</td>\n",
       "      <td>0.034762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061925</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>identity</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.062552</td>\n",
       "      <td>5</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978518</td>\n",
       "      <td>0.015419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054399</td>\n",
       "      <td>0.017001</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>identity</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>9</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.014557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064083</td>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.067576</td>\n",
       "      <td>29</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.883338</td>\n",
       "      <td>0.026063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.089520</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.060972</td>\n",
       "      <td>27</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.921986</td>\n",
       "      <td>0.888118</td>\n",
       "      <td>0.029041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.059368</td>\n",
       "      <td>17</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949532</td>\n",
       "      <td>0.048508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.076125</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.909524</td>\n",
       "      <td>0.078907</td>\n",
       "      <td>14</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.971528</td>\n",
       "      <td>0.009885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.071097</td>\n",
       "      <td>0.012971</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.061556</td>\n",
       "      <td>5</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973738</td>\n",
       "      <td>0.018748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.079626</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.081831</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980933</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.060167</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>identity</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.065113</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978569</td>\n",
       "      <td>0.017374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.061357</td>\n",
       "      <td>0.008590</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>identity</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.065113</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.014557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.083091</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.076625</td>\n",
       "      <td>27</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.843972</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.880974</td>\n",
       "      <td>0.029036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.082924</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.067576</td>\n",
       "      <td>29</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.873677</td>\n",
       "      <td>0.029191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.066694</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.909524</td>\n",
       "      <td>0.041442</td>\n",
       "      <td>14</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954363</td>\n",
       "      <td>0.042037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.066726</td>\n",
       "      <td>0.012912</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.051919</td>\n",
       "      <td>18</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956727</td>\n",
       "      <td>0.042736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.012688</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.095445</td>\n",
       "      <td>11</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983246</td>\n",
       "      <td>0.012258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.077556</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.061703</td>\n",
       "      <td>13</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980882</td>\n",
       "      <td>0.013521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.072662</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>identity</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.054897</td>\n",
       "      <td>11</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980882</td>\n",
       "      <td>0.013521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.063275</td>\n",
       "      <td>0.022326</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>identity</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.065113</td>\n",
       "      <td>2</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976154</td>\n",
       "      <td>0.017748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.078680</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>identity</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980933</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.065397</td>\n",
       "      <td>0.016350</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>identity</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.061556</td>\n",
       "      <td>5</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>0.011582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.023911</td>\n",
       "      <td>0.029488</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.509524</td>\n",
       "      <td>0.243925</td>\n",
       "      <td>66</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.266446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.040342</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.200525</td>\n",
       "      <td>59</td>\n",
       "      <td>0.659420</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.642975</td>\n",
       "      <td>0.246382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.074123</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.081085</td>\n",
       "      <td>22</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.973687</td>\n",
       "      <td>0.014926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.071110</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.099274</td>\n",
       "      <td>20</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980779</td>\n",
       "      <td>0.018104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.060674</td>\n",
       "      <td>0.038536</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.150372</td>\n",
       "      <td>62</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.562648</td>\n",
       "      <td>0.162382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.034177</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.324727</td>\n",
       "      <td>78</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.431905</td>\n",
       "      <td>0.347828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.089497</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.125832</td>\n",
       "      <td>46</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.782198</td>\n",
       "      <td>0.123402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.060083</td>\n",
       "      <td>0.038451</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.480952</td>\n",
       "      <td>0.275676</td>\n",
       "      <td>70</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.695035</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.463357</td>\n",
       "      <td>0.307801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.035264</td>\n",
       "      <td>0.043714</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.509524</td>\n",
       "      <td>0.262065</td>\n",
       "      <td>66</td>\n",
       "      <td>0.311594</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.538853</td>\n",
       "      <td>0.306149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.066725</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.275638</td>\n",
       "      <td>49</td>\n",
       "      <td>0.340580</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.756553</td>\n",
       "      <td>0.294365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.090823</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.131358</td>\n",
       "      <td>37</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.855381</td>\n",
       "      <td>0.118420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.066173</td>\n",
       "      <td>0.041630</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>0.290285</td>\n",
       "      <td>43</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.760972</td>\n",
       "      <td>0.302520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.064185</td>\n",
       "      <td>0.042154</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.299125</td>\n",
       "      <td>53</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.732501</td>\n",
       "      <td>0.263443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.063860</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.229699</td>\n",
       "      <td>56</td>\n",
       "      <td>0.905797</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746377</td>\n",
       "      <td>0.294587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.095133</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.091404</td>\n",
       "      <td>39</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859801</td>\n",
       "      <td>0.133142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>relu</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.204215</td>\n",
       "      <td>72</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.310926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.049510</td>\n",
       "      <td>0.031439</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>relu</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.299805</td>\n",
       "      <td>40</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.756347</td>\n",
       "      <td>0.299237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.034735</td>\n",
       "      <td>0.043288</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.480952</td>\n",
       "      <td>0.211022</td>\n",
       "      <td>70</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.280837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.031528</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.204215</td>\n",
       "      <td>72</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.527187</td>\n",
       "      <td>0.274150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.060827</td>\n",
       "      <td>0.039896</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.242859</td>\n",
       "      <td>53</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.727156</td>\n",
       "      <td>0.283002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.031871</td>\n",
       "      <td>0.038806</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.176986</td>\n",
       "      <td>75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.541371</td>\n",
       "      <td>0.294210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.056161</td>\n",
       "      <td>0.036791</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.719048</td>\n",
       "      <td>0.271217</td>\n",
       "      <td>47</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.682239</td>\n",
       "      <td>0.246756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.048030</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>relu</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.268022</td>\n",
       "      <td>49</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.768322</td>\n",
       "      <td>0.307801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.064048</td>\n",
       "      <td>0.012366</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>relu</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.058454</td>\n",
       "      <td>9</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983246</td>\n",
       "      <td>0.012258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.057995</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.222255</td>\n",
       "      <td>58</td>\n",
       "      <td>0.905797</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.642358</td>\n",
       "      <td>0.235920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.032518</td>\n",
       "      <td>0.039341</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.258672</td>\n",
       "      <td>63</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.513002</td>\n",
       "      <td>0.254090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.027240</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.163242</td>\n",
       "      <td>35</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.819611</td>\n",
       "      <td>0.098428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.028230</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.204215</td>\n",
       "      <td>72</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.527187</td>\n",
       "      <td>0.274150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.030575</td>\n",
       "      <td>0.036762</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.490476</td>\n",
       "      <td>0.224636</td>\n",
       "      <td>68</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.773050</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.479905</td>\n",
       "      <td>0.207284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.048551</td>\n",
       "      <td>0.033096</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>relu</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.247834</td>\n",
       "      <td>55</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.728132</td>\n",
       "      <td>0.284534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.045952</td>\n",
       "      <td>0.033539</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>relu</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.263331</td>\n",
       "      <td>51</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.754137</td>\n",
       "      <td>0.298060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.051843</td>\n",
       "      <td>0.034887</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>relu</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.254801</td>\n",
       "      <td>52</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737589</td>\n",
       "      <td>0.290058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.082209</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>relu</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.031964</td>\n",
       "      <td>24</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.921112</td>\n",
       "      <td>0.051229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.046853      0.015029         0.000383        0.000041   \n",
       "1        0.055086      0.010439         0.000359        0.000010   \n",
       "2        0.061925      0.007204         0.000362        0.000005   \n",
       "3        0.054399      0.017001         0.000418        0.000062   \n",
       "4        0.064083      0.012815         0.000395        0.000023   \n",
       "5        0.089520      0.008664         0.000484        0.000048   \n",
       "6        0.080890      0.004102         0.000416        0.000056   \n",
       "7        0.076125      0.001250         0.000372        0.000016   \n",
       "8        0.071097      0.012971         0.000486        0.000017   \n",
       "9        0.079626      0.003147         0.000442        0.000058   \n",
       "10       0.060167      0.011957         0.000440        0.000041   \n",
       "11       0.061357      0.008590         0.000432        0.000050   \n",
       "12       0.083091      0.005043         0.000460        0.000031   \n",
       "13       0.082924      0.001450         0.000438        0.000011   \n",
       "14       0.066694      0.020762         0.000379        0.000028   \n",
       "15       0.066726      0.012912         0.000354        0.000004   \n",
       "16       0.066700      0.012688         0.000352        0.000006   \n",
       "17       0.077556      0.000924         0.000408        0.000036   \n",
       "18       0.072662      0.009388         0.000422        0.000014   \n",
       "19       0.063275      0.022326         0.000409        0.000019   \n",
       "20       0.078680      0.000498         0.000406        0.000020   \n",
       "21       0.065397      0.016350         0.000360        0.000013   \n",
       "22       0.023911      0.029488         0.000371        0.000027   \n",
       "23       0.040342      0.025696         0.000369        0.000023   \n",
       "24       0.074123      0.001379         0.000403        0.000044   \n",
       "25       0.071110      0.000756         0.000386        0.000011   \n",
       "26       0.060674      0.038536         0.000390        0.000003   \n",
       "27       0.034177      0.039700         0.000405        0.000020   \n",
       "28       0.089497      0.003231         0.000409        0.000019   \n",
       "29       0.060083      0.038451         0.000491        0.000098   \n",
       "..            ...           ...              ...             ...   \n",
       "58       0.035264      0.043714         0.000434        0.000053   \n",
       "59       0.005712      0.002359         0.000397        0.000010   \n",
       "60       0.066725      0.041500         0.000435        0.000021   \n",
       "61       0.090823      0.000537         0.000394        0.000016   \n",
       "62       0.066173      0.041630         0.000510        0.000115   \n",
       "63       0.064185      0.042154         0.000436        0.000056   \n",
       "64       0.063860      0.041772         0.000442        0.000036   \n",
       "65       0.095133      0.000803         0.000503        0.000018   \n",
       "66       0.004001      0.001042         0.000389        0.000055   \n",
       "67       0.004050      0.000138         0.000352        0.000002   \n",
       "68       0.027042      0.031587         0.000364        0.000005   \n",
       "69       0.049510      0.031439         0.000425        0.000063   \n",
       "70       0.034735      0.043288         0.000408        0.000050   \n",
       "71       0.031528      0.038311         0.000385        0.000014   \n",
       "72       0.004552      0.000730         0.000380        0.000005   \n",
       "73       0.060827      0.039896         0.000436        0.000044   \n",
       "74       0.031871      0.038806         0.000454        0.000060   \n",
       "75       0.056161      0.036791         0.000362        0.000007   \n",
       "76       0.048030      0.031356         0.000380        0.000046   \n",
       "77       0.064048      0.012366         0.000467        0.000079   \n",
       "78       0.004572      0.000659         0.000386        0.000001   \n",
       "79       0.057995      0.038200         0.000417        0.000056   \n",
       "80       0.032518      0.039341         0.000391        0.000013   \n",
       "81       0.069843      0.027240         0.000447        0.000012   \n",
       "82       0.028230      0.033299         0.000362        0.000001   \n",
       "83       0.030575      0.036762         0.000357        0.000002   \n",
       "84       0.048551      0.033096         0.000446        0.000062   \n",
       "85       0.045952      0.033539         0.000431        0.000033   \n",
       "86       0.051843      0.034887         0.000403        0.000033   \n",
       "87       0.082209      0.010941         0.000499        0.000027   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "0          identity                     (1,)                     0.01   \n",
       "1          identity                     (1,)                     0.05   \n",
       "2          identity                     (7,)                     0.01   \n",
       "3          identity                     (7,)                     0.05   \n",
       "4          identity                   (1, 6)                     0.01   \n",
       "5          identity                   (1, 6)                     0.05   \n",
       "6          identity                   (2, 5)                     0.01   \n",
       "7          identity                   (2, 5)                     0.05   \n",
       "8          identity                   (3, 4)                     0.01   \n",
       "9          identity                   (3, 4)                     0.05   \n",
       "10         identity                    (11,)                     0.01   \n",
       "11         identity                    (11,)                     0.05   \n",
       "12         identity                  (1, 10)                     0.01   \n",
       "13         identity                  (1, 10)                     0.05   \n",
       "14         identity                   (2, 9)                     0.01   \n",
       "15         identity                   (2, 9)                     0.05   \n",
       "16         identity                   (3, 8)                     0.01   \n",
       "17         identity                   (3, 8)                     0.05   \n",
       "18         identity                   (4, 7)                     0.01   \n",
       "19         identity                   (4, 7)                     0.05   \n",
       "20         identity                   (5, 6)                     0.01   \n",
       "21         identity                   (5, 6)                     0.05   \n",
       "22         logistic                     (1,)                     0.01   \n",
       "23         logistic                     (1,)                     0.05   \n",
       "24         logistic                     (7,)                     0.01   \n",
       "25         logistic                     (7,)                     0.05   \n",
       "26         logistic                   (1, 6)                     0.01   \n",
       "27         logistic                   (1, 6)                     0.05   \n",
       "28         logistic                   (2, 5)                     0.01   \n",
       "29         logistic                   (2, 5)                     0.05   \n",
       "..              ...                      ...                      ...   \n",
       "58             tanh                   (2, 9)                     0.01   \n",
       "59             tanh                   (2, 9)                     0.05   \n",
       "60             tanh                   (3, 8)                     0.01   \n",
       "61             tanh                   (3, 8)                     0.05   \n",
       "62             tanh                   (4, 7)                     0.01   \n",
       "63             tanh                   (4, 7)                     0.05   \n",
       "64             tanh                   (5, 6)                     0.01   \n",
       "65             tanh                   (5, 6)                     0.05   \n",
       "66             relu                     (1,)                     0.01   \n",
       "67             relu                     (1,)                     0.05   \n",
       "68             relu                     (7,)                     0.01   \n",
       "69             relu                     (7,)                     0.05   \n",
       "70             relu                   (1, 6)                     0.01   \n",
       "71             relu                   (1, 6)                     0.05   \n",
       "72             relu                   (2, 5)                     0.01   \n",
       "73             relu                   (2, 5)                     0.05   \n",
       "74             relu                   (3, 4)                     0.01   \n",
       "75             relu                   (3, 4)                     0.05   \n",
       "76             relu                    (11,)                     0.01   \n",
       "77             relu                    (11,)                     0.05   \n",
       "78             relu                  (1, 10)                     0.01   \n",
       "79             relu                  (1, 10)                     0.05   \n",
       "80             relu                   (2, 9)                     0.01   \n",
       "81             relu                   (2, 9)                     0.05   \n",
       "82             relu                   (3, 8)                     0.01   \n",
       "83             relu                   (3, 8)                     0.05   \n",
       "84             relu                   (4, 7)                     0.01   \n",
       "85             relu                   (4, 7)                     0.05   \n",
       "86             relu                   (5, 6)                     0.01   \n",
       "87             relu                   (5, 6)                     0.05   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'activation': 'identity', 'hidden_layer_sizes...           0.861111   \n",
       "1   {'activation': 'identity', 'hidden_layer_sizes...           0.861111   \n",
       "2   {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "3   {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "4   {'activation': 'identity', 'hidden_layer_sizes...           0.875000   \n",
       "5   {'activation': 'identity', 'hidden_layer_sizes...           0.875000   \n",
       "6   {'activation': 'identity', 'hidden_layer_sizes...           0.916667   \n",
       "7   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "8   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "9   {'activation': 'identity', 'hidden_layer_sizes...           0.986111   \n",
       "10  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "11  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "12  {'activation': 'identity', 'hidden_layer_sizes...           0.861111   \n",
       "13  {'activation': 'identity', 'hidden_layer_sizes...           0.875000   \n",
       "14  {'activation': 'identity', 'hidden_layer_sizes...           0.916667   \n",
       "15  {'activation': 'identity', 'hidden_layer_sizes...           0.930556   \n",
       "16  {'activation': 'identity', 'hidden_layer_sizes...           0.986111   \n",
       "17  {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "18  {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "19  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "20  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "21  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "22  {'activation': 'logistic', 'hidden_layer_sizes...           0.847222   \n",
       "23  {'activation': 'logistic', 'hidden_layer_sizes...           0.680556   \n",
       "24  {'activation': 'logistic', 'hidden_layer_sizes...           0.958333   \n",
       "25  {'activation': 'logistic', 'hidden_layer_sizes...           0.972222   \n",
       "26  {'activation': 'logistic', 'hidden_layer_sizes...           0.666667   \n",
       "27  {'activation': 'logistic', 'hidden_layer_sizes...           0.861111   \n",
       "28  {'activation': 'logistic', 'hidden_layer_sizes...           0.902778   \n",
       "29  {'activation': 'logistic', 'hidden_layer_sizes...           0.680556   \n",
       "..                                                ...                ...   \n",
       "58  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.319444   \n",
       "59  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "60  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "61  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.958333   \n",
       "62  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.930556   \n",
       "63  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.972222   \n",
       "64  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.861111   \n",
       "65  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.847222   \n",
       "66  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "67  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "68  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "69  {'activation': 'relu', 'hidden_layer_sizes': (...           0.972222   \n",
       "70  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "71  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "72  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "73  {'activation': 'relu', 'hidden_layer_sizes': (...           0.902778   \n",
       "74  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "75  {'activation': 'relu', 'hidden_layer_sizes': (...           0.875000   \n",
       "76  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "77  {'activation': 'relu', 'hidden_layer_sizes': (...           0.958333   \n",
       "78  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "79  {'activation': 'relu', 'hidden_layer_sizes': (...           0.875000   \n",
       "80  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "81  {'activation': 'relu', 'hidden_layer_sizes': (...           0.986111   \n",
       "82  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "83  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "84  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "85  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "86  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "87  {'activation': 'relu', 'hidden_layer_sizes': (...           0.888889   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.913043           0.753623         0.842857        0.065948   \n",
       "1            0.913043           0.811594         0.861905        0.041124   \n",
       "2            0.985507           0.840580         0.928571        0.062552   \n",
       "3            0.985507           0.826087         0.923810        0.069261   \n",
       "4            0.913043           0.753623         0.847619        0.067576   \n",
       "5            0.913043           0.768116         0.852381        0.060972   \n",
       "6            0.971014           0.826087         0.904762        0.059368   \n",
       "7            0.956522           0.797101         0.909524        0.078907   \n",
       "8            0.971014           0.840580         0.928571        0.061556   \n",
       "9            0.985507           0.811594         0.928571        0.081831   \n",
       "10           0.985507           0.840580         0.933333        0.065113   \n",
       "11           0.985507           0.840580         0.933333        0.065113   \n",
       "12           0.942029           0.753623         0.852381        0.076625   \n",
       "13           0.913043           0.753623         0.847619        0.067576   \n",
       "14           0.956522           0.855072         0.909524        0.041442   \n",
       "15           0.942029           0.826087         0.900000        0.051919   \n",
       "16           0.985507           0.782609         0.919048        0.095445   \n",
       "17           0.956522           0.826087         0.914286        0.061703   \n",
       "18           0.956522           0.840580         0.919048        0.054897   \n",
       "19           0.985507           0.840580         0.933333        0.065113   \n",
       "20           0.985507           0.855072         0.938095        0.058332   \n",
       "21           0.971014           0.840580         0.928571        0.061556   \n",
       "22           0.333333           0.333333         0.509524        0.243925   \n",
       "23           0.333333           0.811594         0.609524        0.200525   \n",
       "24           0.913043           0.768116         0.880952        0.081085   \n",
       "25           0.956522           0.753623         0.895238        0.099274   \n",
       "26           0.637681           0.333333         0.547619        0.150372   \n",
       "27           0.086957           0.333333         0.433333        0.324727   \n",
       "28           0.637681           0.637681         0.728571        0.125832   \n",
       "29           0.666667           0.086957         0.480952        0.275676   \n",
       "..                ...                ...              ...             ...   \n",
       "58           0.884058           0.333333         0.509524        0.262065   \n",
       "59           0.333333           0.333333         0.333333        0.000000   \n",
       "60           0.985507           0.797101         0.700000        0.275638   \n",
       "61           0.637681           0.797101         0.800000        0.131358   \n",
       "62           0.971014           0.333333         0.747619        0.290285   \n",
       "63           0.768116           0.260870         0.671429        0.299125   \n",
       "64           0.333333           0.768116         0.657143        0.229699   \n",
       "65           0.637681           0.811594         0.766667        0.091404   \n",
       "66           0.333333           0.333333         0.333333        0.000000   \n",
       "67           0.333333           0.333333         0.333333        0.000000   \n",
       "68           0.333333           0.768116         0.476190        0.204215   \n",
       "69           0.971014           0.333333         0.761905        0.299805   \n",
       "70           0.333333           0.782609         0.480952        0.211022   \n",
       "71           0.333333           0.768116         0.476190        0.204215   \n",
       "72           0.333333           0.333333         0.333333        0.000000   \n",
       "73           0.333333           0.768116         0.671429        0.242859   \n",
       "74           0.333333           0.710145         0.457143        0.176986   \n",
       "75           0.942029           0.333333         0.719048        0.271217   \n",
       "76           0.942029           0.840580         0.700000        0.268022   \n",
       "77           0.971014           0.840580         0.923810        0.058454   \n",
       "78           0.333333           0.333333         0.333333        0.000000   \n",
       "79           0.637681           0.333333         0.619048        0.222255   \n",
       "80           0.884058           0.333333         0.514286        0.258672   \n",
       "81           0.913043           0.608696         0.838095        0.163242   \n",
       "82           0.333333           0.768116         0.476190        0.204215   \n",
       "83           0.811594           0.333333         0.490476        0.224636   \n",
       "84           0.913043           0.768116         0.666667        0.247834   \n",
       "85           0.942029           0.811594         0.690476        0.263331   \n",
       "86           0.884058           0.855072         0.685714        0.254801   \n",
       "87           0.898551           0.826087         0.871429        0.031964   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                33            0.884058            0.851064   \n",
       "1                25            0.891304            0.851064   \n",
       "2                 5            0.971014            0.964539   \n",
       "3                 9            0.985507            0.964539   \n",
       "4                29            0.884058            0.851064   \n",
       "5                27            0.891304            0.851064   \n",
       "6                17            0.884058            0.964539   \n",
       "7                14            0.985507            0.964539   \n",
       "8                 5            0.963768            0.957447   \n",
       "9                 5            0.978261            0.964539   \n",
       "10                2            0.978261            0.957447   \n",
       "11                2            0.985507            0.964539   \n",
       "12               27            0.884058            0.843972   \n",
       "13               29            0.855072            0.851064   \n",
       "14               14            0.898551            0.964539   \n",
       "15               18            0.898551            0.971631   \n",
       "16               11            0.971014            0.978723   \n",
       "17               13            0.971014            0.971631   \n",
       "18               11            0.971014            0.971631   \n",
       "19                2            0.971014            0.957447   \n",
       "20                1            0.978261            0.964539   \n",
       "21                5            0.985507            0.971631   \n",
       "22               66            0.898551            0.333333   \n",
       "23               59            0.659420            0.333333   \n",
       "24               22            0.956522            0.971631   \n",
       "25               20            0.956522            0.985816   \n",
       "26               62            0.666667            0.687943   \n",
       "27               78            0.898551            0.063830   \n",
       "28               46            0.956522            0.687943   \n",
       "29               70            0.666667            0.695035   \n",
       "..              ...                 ...                 ...   \n",
       "58               66            0.311594            0.971631   \n",
       "59               79            0.333333            0.333333   \n",
       "60               49            0.340580            0.978723   \n",
       "61               37            0.942029            0.687943   \n",
       "62               43            0.963768            0.985816   \n",
       "63               53            0.949275            0.886525   \n",
       "64               56            0.905797            0.333333   \n",
       "65               39            0.898551            0.680851   \n",
       "66               79            0.333333            0.333333   \n",
       "67               79            0.333333            0.333333   \n",
       "68               72            0.333333            0.333333   \n",
       "69               40            0.978261            0.957447   \n",
       "70               70            0.333333            0.333333   \n",
       "71               72            0.333333            0.333333   \n",
       "72               79            0.333333            0.333333   \n",
       "73               53            0.862319            0.333333   \n",
       "74               75            0.333333            0.333333   \n",
       "75               47            0.862319            0.851064   \n",
       "76               49            0.333333            0.971631   \n",
       "77                9            0.971014            0.978723   \n",
       "78               79            0.333333            0.333333   \n",
       "79               58            0.905797            0.687943   \n",
       "80               63            0.333333            0.872340   \n",
       "81               35            0.898551            0.879433   \n",
       "82               72            0.333333            0.333333   \n",
       "83               68            0.333333            0.773050   \n",
       "84               55            0.333333            0.858156   \n",
       "85               51            0.333333            0.943262   \n",
       "86               52            0.333333            0.879433   \n",
       "87               24            0.876812            0.893617   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.921986          0.885703         0.028977  \n",
       "1             0.936170          0.892846         0.034762  \n",
       "2             1.000000          0.978518         0.015419  \n",
       "3             1.000000          0.983349         0.014557  \n",
       "4             0.914894          0.883338         0.026063  \n",
       "5             0.921986          0.888118         0.029041  \n",
       "6             1.000000          0.949532         0.048508  \n",
       "7             0.964539          0.971528         0.009885  \n",
       "8             1.000000          0.973738         0.018748  \n",
       "9             1.000000          0.980933         0.014600  \n",
       "10            1.000000          0.978569         0.017374  \n",
       "11            1.000000          0.983349         0.014557  \n",
       "12            0.914894          0.880974         0.029036  \n",
       "13            0.914894          0.873677         0.029191  \n",
       "14            1.000000          0.954363         0.042037  \n",
       "15            1.000000          0.956727         0.042736  \n",
       "16            1.000000          0.983246         0.012258  \n",
       "17            1.000000          0.980882         0.013521  \n",
       "18            1.000000          0.980882         0.013521  \n",
       "19            1.000000          0.976154         0.017748  \n",
       "20            1.000000          0.980933         0.014600  \n",
       "21            1.000000          0.985713         0.011582  \n",
       "22            0.333333          0.521739         0.266446  \n",
       "23            0.936170          0.642975         0.246382  \n",
       "24            0.992908          0.973687         0.014926  \n",
       "25            1.000000          0.980779         0.018104  \n",
       "26            0.333333          0.562648         0.162382  \n",
       "27            0.333333          0.431905         0.347828  \n",
       "28            0.702128          0.782198         0.123402  \n",
       "29            0.028369          0.463357         0.307801  \n",
       "..                 ...               ...              ...  \n",
       "58            0.333333          0.538853         0.306149  \n",
       "59            0.333333          0.333333         0.000000  \n",
       "60            0.950355          0.756553         0.294365  \n",
       "61            0.936170          0.855381         0.118420  \n",
       "62            0.333333          0.760972         0.302520  \n",
       "63            0.361702          0.732501         0.263443  \n",
       "64            1.000000          0.746377         0.294587  \n",
       "65            1.000000          0.859801         0.133142  \n",
       "66            0.333333          0.333333         0.000000  \n",
       "67            0.333333          0.333333         0.000000  \n",
       "68            0.992908          0.553191         0.310926  \n",
       "69            0.333333          0.756347         0.299237  \n",
       "70            0.929078          0.531915         0.280837  \n",
       "71            0.914894          0.527187         0.274150  \n",
       "72            0.333333          0.333333         0.000000  \n",
       "73            0.985816          0.727156         0.283002  \n",
       "74            0.957447          0.541371         0.294210  \n",
       "75            0.333333          0.682239         0.246756  \n",
       "76            1.000000          0.768322         0.307801  \n",
       "77            1.000000          0.983246         0.012258  \n",
       "78            0.333333          0.333333         0.000000  \n",
       "79            0.333333          0.642358         0.235920  \n",
       "80            0.333333          0.513002         0.254090  \n",
       "81            0.680851          0.819611         0.098428  \n",
       "82            0.914894          0.527187         0.274150  \n",
       "83            0.333333          0.479905         0.207284  \n",
       "84            0.992908          0.728132         0.284534  \n",
       "85            0.985816          0.754137         0.298060  \n",
       "86            1.000000          0.737589         0.290058  \n",
       "87            0.992908          0.921112         0.051229  \n",
       "\n",
       "[88 rows x 19 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas do modelo que o obteve a melhor média de acurácia entre os folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.065397</td>\n",
       "      <td>0.01635</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>identity</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.84058</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.061556</td>\n",
       "      <td>5</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>0.011582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "21       0.065397       0.01635          0.00036        0.000013   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "21         identity                   (5, 6)                     0.05   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "21  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "21           0.971014            0.84058         0.928571        0.061556   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "21                5            0.985507            0.971631   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "21                 1.0          0.985713         0.011582  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results['mean_train_score']==max(results['mean_train_score'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características do melhor modelo que endereça a tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 6), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = clf.best_estimator_.predict(X)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904762"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
