{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto Prático 4\n",
    "\n",
    "**Universidade do Estado do Amazonas**  \n",
    "**Escola Superior de Tecnologia**  \n",
    "**Professora:** Elloá B. Guedes  \n",
    "**Alunos:** Juliany Raiol, Raí Soledade, Richardson Souza  \n",
    "**Disciplina:** Redes Neurais Artificiais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado de Máquina com tarefa de classificação aplicado no dataset  de variedades de trigo\n",
    "\n",
    "### Introdução\n",
    "\n",
    "Três variedades de trigo (Kama, Rosa e Canadian) possuem sementes muito parecidas,\n",
    "entretanto diferentes. Um grupo de pesquisadores poloneses coletou 70 amostras de cada\n",
    "tipo e, usando uma técnica particular de raio-X, coletou medidas geométricas destas\n",
    "sementes, a citar: área, perímetro, compactude, comprimento, largura, coeficiente de\n",
    "assimetria e comprimento do sulco da semente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos utilizados no projeto\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Area\", \"Perimeter\", \"Compactness\", \"Length\", \"Width\", \"Asymmetry\", \"Groove\", \"Seed\"]\n",
    "\n",
    "df = pd.read_csv('../../data/seeds_dataset.txt', delim_whitespace=True, names = names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = atributos preditores, y = atributo alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Seed', axis=1)\n",
    "y = df['Seed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição dos parâmetros de taxa de aprendizado, neurônios na camada de entrada e saída, funções de ativação e o alfa da regra da pirâmide geométrica utilizada para calcular a quantidade de neurônios nas camadas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate  = [0.01, 0.05]\n",
    "alpha = [0.5, 2, 3]\n",
    "\n",
    "neuron_out = 2\n",
    "neuron_ini = 7\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo da quantidade de neurônios nas camadas ocultas utilizando a regra da pirâmide geométrica.\n",
    "\n",
    "\\begin{align}\n",
    "\\dot{N_{h}} & = \\alpha.\\sqrt{\\dot{N_{i} . \\dot{N_{o}}}}\n",
    "\\end{align}\n",
    "\n",
    "<strong> Nh </strong> é o número de neurônios ocultos (a serem distribuídos em uma ou duas camadas\n",
    "ocultas)\n",
    "\n",
    "<strong>Ni</strong> é o número de neurônios na camada de entrada\n",
    "\n",
    "<strong>No</strong> é o número de neurônios\n",
    "na camada de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de neurônios nas camadas ocultas a serem testadas respectivamente:  [1, 7, 11]\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "for a in alpha:\n",
    "    n.append(int( a * np.sqrt((neuron_ini*neuron_out))))\n",
    "print(\"Quantidade de neurônios nas camadas ocultas a serem testadas respectivamente: \", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetro que define uma série de combinações de neurônios distribuídos em 1 ou 2 camadas, de acordo com a quantidade de neurônios calculada anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = [(1,), (7,),(1,6),(2,5),(3,4), (11,),(1,10),(2,9),(3,8),(4,7),(5,6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição dos parâmetros para inicialização dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict([\n",
    "                ('hidden_layer_sizes', hidden_layer),\n",
    "                ('learning_rate_init', rate),\n",
    "                ('activation', activation_functions)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No treinamento das redes neurais, o solver escolhido foi o LBFGS pois ele é o que se comporta melhor com datasets com poucos dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'hidden_layer_sizes': [(1,), (7,), (1, 6), (2, 5), (3, 4), (11,), (1, 10), (2, 9), (3, 8), (4, 7), (5, 6)], 'learning_rate_init': [0.01, 0.05], 'activation': ['identity', 'logistic', 'tanh', 'relu']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(MLPClassifier(solver='lbfgs'), parameters, iid=True, cv = 3, return_train_score=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listagem de todas as redes neurais geradas pelo GridSearchCV, com k-fold de tamanho 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135941</td>\n",
       "      <td>0.141183</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>5.463353e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.067576</td>\n",
       "      <td>33</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.871261</td>\n",
       "      <td>0.030881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036299</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>9.381164e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.047081</td>\n",
       "      <td>29</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.921986</td>\n",
       "      <td>0.888118</td>\n",
       "      <td>0.029041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047110</td>\n",
       "      <td>0.022264</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>1.857014e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.065347</td>\n",
       "      <td>12</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983297</td>\n",
       "      <td>0.012117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>7.439279e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.065113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.014557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054199</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>1.644954e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.067576</td>\n",
       "      <td>33</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.885754</td>\n",
       "      <td>0.026352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.054986</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>1.191351e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.077447</td>\n",
       "      <td>29</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.873677</td>\n",
       "      <td>0.029191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.055007</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>2.355965e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.116159</td>\n",
       "      <td>25</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.952616</td>\n",
       "      <td>0.029030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.050661</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>5.388940e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983297</td>\n",
       "      <td>0.012117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.052154</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>4.086497e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.058454</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978569</td>\n",
       "      <td>0.017374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.052812</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>2.219329e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.112667</td>\n",
       "      <td>18</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.976205</td>\n",
       "      <td>0.014550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.043776</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>1.590212e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.061556</td>\n",
       "      <td>3</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985764</td>\n",
       "      <td>0.015297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.037431</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>1.455764e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.065113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980933</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.054175</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>1.094362e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.064923</td>\n",
       "      <td>31</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.843972</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.885805</td>\n",
       "      <td>0.030324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.050294</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>4.536223e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>27</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.892846</td>\n",
       "      <td>0.034762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.055419</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>9.246899e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.109205</td>\n",
       "      <td>19</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.964076</td>\n",
       "      <td>0.023732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.053975</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>1.678026e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.060604</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980933</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>5.745179e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.058577</td>\n",
       "      <td>5</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978518</td>\n",
       "      <td>0.015419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.053272</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>5.345127e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>5</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>0.011582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.046115</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>1.537918e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>5</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985764</td>\n",
       "      <td>0.015297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>1.389116e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.105868</td>\n",
       "      <td>15</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985764</td>\n",
       "      <td>0.015297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.054023</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>2.444175e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.062552</td>\n",
       "      <td>3</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.014557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.043481</td>\n",
       "      <td>0.014068</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>identity</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968856</td>\n",
       "      <td>0.023863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.146394e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>6.880716e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.052061</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>1.946809e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.036976</td>\n",
       "      <td>22</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.940127</td>\n",
       "      <td>0.034523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.051037</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>1.351366e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.071911</td>\n",
       "      <td>19</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.954672</td>\n",
       "      <td>0.017015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.063004</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>1.343209e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.138940</td>\n",
       "      <td>45</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>0.822078</td>\n",
       "      <td>0.096834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.063142</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>2.278890e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.063164</td>\n",
       "      <td>37</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.909549</td>\n",
       "      <td>0.023294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.042257</td>\n",
       "      <td>0.026653</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>1.266739e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.266149</td>\n",
       "      <td>61</td>\n",
       "      <td>0.905797</td>\n",
       "      <td>0.248227</td>\n",
       "      <td>0.645390</td>\n",
       "      <td>0.599805</td>\n",
       "      <td>0.270380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.041851</td>\n",
       "      <td>0.026198</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>1.149915e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.101449</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.323685</td>\n",
       "      <td>62</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.668311</td>\n",
       "      <td>0.357690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>5.619580e-07</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.047735</td>\n",
       "      <td>0.029690</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>4.787024e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.405797</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.196216</td>\n",
       "      <td>53</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.432624</td>\n",
       "      <td>0.734505</td>\n",
       "      <td>0.213730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.029221</td>\n",
       "      <td>0.031550</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>5.281939e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.227898</td>\n",
       "      <td>63</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.545380</td>\n",
       "      <td>0.251402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.071679</td>\n",
       "      <td>0.045737</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>7.652019e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.222029</td>\n",
       "      <td>55</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.659215</td>\n",
       "      <td>0.249391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.099149</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>7.837652e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.069988</td>\n",
       "      <td>23</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.943211</td>\n",
       "      <td>0.060415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.095193</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>9.744526e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>33</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.904615</td>\n",
       "      <td>0.032398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.103916</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>1.601452e-04</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.071718</td>\n",
       "      <td>15</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.971477</td>\n",
       "      <td>0.005603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.085413</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>1.450531e-04</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.089181</td>\n",
       "      <td>42</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.017911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.252861e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.031012</td>\n",
       "      <td>0.036171</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>6.779813e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.490476</td>\n",
       "      <td>0.224636</td>\n",
       "      <td>72</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.536643</td>\n",
       "      <td>0.287523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.074731</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>4.666471e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.065362</td>\n",
       "      <td>15</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988077</td>\n",
       "      <td>0.008874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.074705</td>\n",
       "      <td>0.007908</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>9.163300e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.085531</td>\n",
       "      <td>12</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.954774</td>\n",
       "      <td>0.020305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.049354</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>5.085729e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.509524</td>\n",
       "      <td>0.243925</td>\n",
       "      <td>69</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.514493</td>\n",
       "      <td>0.256198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.061354</td>\n",
       "      <td>0.046126</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>9.150823e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.255873</td>\n",
       "      <td>56</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.704492</td>\n",
       "      <td>0.264374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>7.229139e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>5.384824e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.026111</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>3.287373e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.519048</td>\n",
       "      <td>0.265479</td>\n",
       "      <td>68</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.290867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>3.635933e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.057809</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>1.406642e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.084282</td>\n",
       "      <td>19</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.900709</td>\n",
       "      <td>0.952564</td>\n",
       "      <td>0.036668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.039110</td>\n",
       "      <td>0.024852</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>2.999171e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.256957</td>\n",
       "      <td>51</td>\n",
       "      <td>0.905797</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.741649</td>\n",
       "      <td>0.290565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.026958</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>5.363659e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.263702</td>\n",
       "      <td>65</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.509662</td>\n",
       "      <td>0.249366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.005890</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>8.410564e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.053087</td>\n",
       "      <td>0.033624</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>1.160410e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.243999</td>\n",
       "      <td>53</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.724792</td>\n",
       "      <td>0.280853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.031613</td>\n",
       "      <td>0.037837</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>7.561775e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.504762</td>\n",
       "      <td>0.237332</td>\n",
       "      <td>71</td>\n",
       "      <td>0.905797</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.524155</td>\n",
       "      <td>0.269862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>4.400529e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.035581</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>7.015406e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.285901</td>\n",
       "      <td>64</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.548463</td>\n",
       "      <td>0.304240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.068686</td>\n",
       "      <td>0.046201</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>9.535836e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.217245</td>\n",
       "      <td>58</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.727361</td>\n",
       "      <td>0.279925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.047182</td>\n",
       "      <td>0.043665</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>2.082295e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.623810</td>\n",
       "      <td>0.239174</td>\n",
       "      <td>59</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.632747</td>\n",
       "      <td>0.227391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.059921</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>6.886652e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.287504</td>\n",
       "      <td>49</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.744372</td>\n",
       "      <td>0.290699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.068476</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>1.476699e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.020124</td>\n",
       "      <td>31</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940025</td>\n",
       "      <td>0.050344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.135941      0.141183         0.000357    5.463353e-05   \n",
       "1        0.036299      0.005218         0.000309    9.381164e-06   \n",
       "2        0.047110      0.022264         0.000334    1.857014e-06   \n",
       "3        0.043567      0.003085         0.000365    7.439279e-05   \n",
       "4        0.054199      0.002430         0.000350    1.644954e-05   \n",
       "5        0.054986      0.000695         0.000330    1.191351e-05   \n",
       "6        0.055007      0.000889         0.000353    2.355965e-05   \n",
       "7        0.050661      0.002991         0.000312    5.388940e-06   \n",
       "8        0.052154      0.000413         0.000348    4.086497e-05   \n",
       "9        0.052812      0.000774         0.000324    2.219329e-05   \n",
       "10       0.043776      0.003893         0.000318    1.590212e-05   \n",
       "11       0.037431      0.012556         0.000316    1.455764e-05   \n",
       "12       0.054175      0.004356         0.000337    1.094362e-05   \n",
       "13       0.050294      0.009735         0.000322    4.536223e-06   \n",
       "14       0.055419      0.000129         0.000325    9.246899e-06   \n",
       "15       0.053975      0.000550         0.000331    1.678026e-05   \n",
       "16       0.053100      0.000383         0.000315    5.745179e-06   \n",
       "17       0.053272      0.000345         0.000356    5.345127e-05   \n",
       "18       0.046115      0.012787         0.000328    1.537918e-05   \n",
       "19       0.054600      0.000273         0.000327    1.389116e-05   \n",
       "20       0.054023      0.000832         0.000325    2.444175e-05   \n",
       "21       0.043481      0.014068         0.000312    4.052337e-07   \n",
       "22       0.002886      0.000473         0.000300    1.146394e-05   \n",
       "23       0.003865      0.000251         0.000297    6.880716e-06   \n",
       "24       0.052061      0.000233         0.000348    1.946809e-05   \n",
       "25       0.051037      0.000551         0.000336    1.351366e-05   \n",
       "26       0.063004      0.000587         0.000350    1.343209e-05   \n",
       "27       0.063142      0.000136         0.000355    2.278890e-05   \n",
       "28       0.042257      0.026653         0.000334    1.266739e-05   \n",
       "29       0.041851      0.026198         0.000321    1.149915e-05   \n",
       "..            ...           ...              ...             ...   \n",
       "58       0.003189      0.000264         0.000324    5.619580e-07   \n",
       "59       0.047735      0.029690         0.000403    4.787024e-05   \n",
       "60       0.029221      0.031550         0.000383    5.281939e-05   \n",
       "61       0.071679      0.045737         0.000640    7.652019e-05   \n",
       "62       0.099149      0.012122         0.000436    7.837652e-06   \n",
       "63       0.095193      0.009208         0.000607    9.744526e-05   \n",
       "64       0.103916      0.005361         0.000666    1.601452e-04   \n",
       "65       0.085413      0.005117         0.000515    1.450531e-04   \n",
       "66       0.007049      0.001915         0.000749    1.252861e-04   \n",
       "67       0.031012      0.036171         0.000572    6.779813e-05   \n",
       "68       0.074731      0.016695         0.000474    4.666471e-05   \n",
       "69       0.074705      0.007908         0.000535    9.163300e-05   \n",
       "70       0.049354      0.061788         0.000663    5.085729e-05   \n",
       "71       0.061354      0.046126         0.000553    9.150823e-05   \n",
       "72       0.003965      0.000549         0.000437    7.229139e-05   \n",
       "73       0.003714      0.000921         0.000375    5.384824e-05   \n",
       "74       0.026111      0.032034         0.000350    3.287373e-05   \n",
       "75       0.003819      0.000825         0.000370    3.635933e-05   \n",
       "76       0.057809      0.000933         0.000489    1.406642e-04   \n",
       "77       0.039110      0.024852         0.000356    2.999171e-05   \n",
       "78       0.026958      0.032028         0.000552    5.363659e-05   \n",
       "79       0.005890      0.000464         0.000530    8.410564e-05   \n",
       "80       0.053087      0.033624         0.000480    1.160410e-04   \n",
       "81       0.031613      0.037837         0.000571    7.561775e-05   \n",
       "82       0.005323      0.000982         0.000425    4.400529e-06   \n",
       "83       0.030598      0.035581         0.000507    7.015406e-05   \n",
       "84       0.068686      0.046201         0.000557    9.535836e-05   \n",
       "85       0.047182      0.043665         0.000739    2.082295e-04   \n",
       "86       0.059921      0.041102         0.000520    6.886652e-05   \n",
       "87       0.068476      0.005581         0.000397    1.476699e-05   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "0          identity                     (1,)                     0.01   \n",
       "1          identity                     (1,)                     0.05   \n",
       "2          identity                     (7,)                     0.01   \n",
       "3          identity                     (7,)                     0.05   \n",
       "4          identity                   (1, 6)                     0.01   \n",
       "5          identity                   (1, 6)                     0.05   \n",
       "6          identity                   (2, 5)                     0.01   \n",
       "7          identity                   (2, 5)                     0.05   \n",
       "8          identity                   (3, 4)                     0.01   \n",
       "9          identity                   (3, 4)                     0.05   \n",
       "10         identity                    (11,)                     0.01   \n",
       "11         identity                    (11,)                     0.05   \n",
       "12         identity                  (1, 10)                     0.01   \n",
       "13         identity                  (1, 10)                     0.05   \n",
       "14         identity                   (2, 9)                     0.01   \n",
       "15         identity                   (2, 9)                     0.05   \n",
       "16         identity                   (3, 8)                     0.01   \n",
       "17         identity                   (3, 8)                     0.05   \n",
       "18         identity                   (4, 7)                     0.01   \n",
       "19         identity                   (4, 7)                     0.05   \n",
       "20         identity                   (5, 6)                     0.01   \n",
       "21         identity                   (5, 6)                     0.05   \n",
       "22         logistic                     (1,)                     0.01   \n",
       "23         logistic                     (1,)                     0.05   \n",
       "24         logistic                     (7,)                     0.01   \n",
       "25         logistic                     (7,)                     0.05   \n",
       "26         logistic                   (1, 6)                     0.01   \n",
       "27         logistic                   (1, 6)                     0.05   \n",
       "28         logistic                   (2, 5)                     0.01   \n",
       "29         logistic                   (2, 5)                     0.05   \n",
       "..              ...                      ...                      ...   \n",
       "58             tanh                   (2, 9)                     0.01   \n",
       "59             tanh                   (2, 9)                     0.05   \n",
       "60             tanh                   (3, 8)                     0.01   \n",
       "61             tanh                   (3, 8)                     0.05   \n",
       "62             tanh                   (4, 7)                     0.01   \n",
       "63             tanh                   (4, 7)                     0.05   \n",
       "64             tanh                   (5, 6)                     0.01   \n",
       "65             tanh                   (5, 6)                     0.05   \n",
       "66             relu                     (1,)                     0.01   \n",
       "67             relu                     (1,)                     0.05   \n",
       "68             relu                     (7,)                     0.01   \n",
       "69             relu                     (7,)                     0.05   \n",
       "70             relu                   (1, 6)                     0.01   \n",
       "71             relu                   (1, 6)                     0.05   \n",
       "72             relu                   (2, 5)                     0.01   \n",
       "73             relu                   (2, 5)                     0.05   \n",
       "74             relu                   (3, 4)                     0.01   \n",
       "75             relu                   (3, 4)                     0.05   \n",
       "76             relu                    (11,)                     0.01   \n",
       "77             relu                    (11,)                     0.05   \n",
       "78             relu                  (1, 10)                     0.01   \n",
       "79             relu                  (1, 10)                     0.05   \n",
       "80             relu                   (2, 9)                     0.01   \n",
       "81             relu                   (2, 9)                     0.05   \n",
       "82             relu                   (3, 8)                     0.01   \n",
       "83             relu                   (3, 8)                     0.05   \n",
       "84             relu                   (4, 7)                     0.01   \n",
       "85             relu                   (4, 7)                     0.05   \n",
       "86             relu                   (5, 6)                     0.01   \n",
       "87             relu                   (5, 6)                     0.05   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'activation': 'identity', 'hidden_layer_sizes...           0.875000   \n",
       "1   {'activation': 'identity', 'hidden_layer_sizes...           0.861111   \n",
       "2   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "3   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "4   {'activation': 'identity', 'hidden_layer_sizes...           0.875000   \n",
       "5   {'activation': 'identity', 'hidden_layer_sizes...           0.875000   \n",
       "6   {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "7   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "8   {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "9   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "10  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "11  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "12  {'activation': 'identity', 'hidden_layer_sizes...           0.861111   \n",
       "13  {'activation': 'identity', 'hidden_layer_sizes...           0.861111   \n",
       "14  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "15  {'activation': 'identity', 'hidden_layer_sizes...           0.944444   \n",
       "16  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "17  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "18  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "19  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "20  {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "21  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "22  {'activation': 'logistic', 'hidden_layer_sizes...           0.333333   \n",
       "23  {'activation': 'logistic', 'hidden_layer_sizes...           0.333333   \n",
       "24  {'activation': 'logistic', 'hidden_layer_sizes...           0.875000   \n",
       "25  {'activation': 'logistic', 'hidden_layer_sizes...           0.986111   \n",
       "26  {'activation': 'logistic', 'hidden_layer_sizes...           0.861111   \n",
       "27  {'activation': 'logistic', 'hidden_layer_sizes...           0.875000   \n",
       "28  {'activation': 'logistic', 'hidden_layer_sizes...           0.861111   \n",
       "29  {'activation': 'logistic', 'hidden_layer_sizes...           0.847222   \n",
       "..                                                ...                ...   \n",
       "58  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "59  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.861111   \n",
       "60  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.861111   \n",
       "61  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.958333   \n",
       "62  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.944444   \n",
       "63  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.819444   \n",
       "64  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.986111   \n",
       "65  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.833333   \n",
       "66  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "67  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "68  {'activation': 'relu', 'hidden_layer_sizes': (...           0.944444   \n",
       "69  {'activation': 'relu', 'hidden_layer_sizes': (...           0.986111   \n",
       "70  {'activation': 'relu', 'hidden_layer_sizes': (...           0.847222   \n",
       "71  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "72  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "73  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "74  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "75  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "76  {'activation': 'relu', 'hidden_layer_sizes': (...           0.986111   \n",
       "77  {'activation': 'relu', 'hidden_layer_sizes': (...           0.861111   \n",
       "78  {'activation': 'relu', 'hidden_layer_sizes': (...           0.888889   \n",
       "79  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "80  {'activation': 'relu', 'hidden_layer_sizes': (...           0.875000   \n",
       "81  {'activation': 'relu', 'hidden_layer_sizes': (...           0.833333   \n",
       "82  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "83  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "84  {'activation': 'relu', 'hidden_layer_sizes': (...           0.847222   \n",
       "85  {'activation': 'relu', 'hidden_layer_sizes': (...           0.916667   \n",
       "86  {'activation': 'relu', 'hidden_layer_sizes': (...           0.972222   \n",
       "87  {'activation': 'relu', 'hidden_layer_sizes': (...           0.875000   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.913043           0.753623         0.847619        0.067576   \n",
       "1            0.913043           0.797101         0.857143        0.047081   \n",
       "2            0.956522           0.826087         0.919048        0.065347   \n",
       "3            0.985507           0.840580         0.933333        0.065113   \n",
       "4            0.913043           0.753623         0.847619        0.067576   \n",
       "5            0.942029           0.753623         0.857143        0.077447   \n",
       "6            0.956522           0.710145         0.876190        0.116159   \n",
       "7            0.971014           0.826087         0.923810        0.068363   \n",
       "8            0.971014           0.840580         0.923810        0.058454   \n",
       "9            0.985507           0.739130         0.900000        0.112667   \n",
       "10           0.971014           0.840580         0.928571        0.061556   \n",
       "11           0.985507           0.840580         0.933333        0.065113   \n",
       "12           0.927536           0.768116         0.852381        0.064923   \n",
       "13           0.913043           0.811594         0.861905        0.041124   \n",
       "14           0.971014           0.739130         0.895238        0.109205   \n",
       "15           0.985507           0.840580         0.923810        0.060604   \n",
       "16           0.956522           0.840580         0.923810        0.058577   \n",
       "17           0.971014           0.826087         0.923810        0.068363   \n",
       "18           0.971014           0.826087         0.923810        0.068363   \n",
       "19           0.985507           0.753623         0.904762        0.105868   \n",
       "20           0.985507           0.840580         0.928571        0.062552   \n",
       "21           0.971014           0.826087         0.923810        0.068363   \n",
       "22           0.333333           0.333333         0.333333        0.000000   \n",
       "23           0.333333           0.333333         0.333333        0.000000   \n",
       "24           0.942029           0.855072         0.890476        0.036976   \n",
       "25           0.884058           0.811594         0.895238        0.071911   \n",
       "26           0.913043           0.594203         0.790476        0.138940   \n",
       "27           0.898551           0.753623         0.842857        0.063164   \n",
       "28           0.217391           0.623188         0.571429        0.266149   \n",
       "29           0.101449           0.710145         0.557143        0.323685   \n",
       "..                ...                ...              ...             ...   \n",
       "58           0.333333           0.333333         0.333333        0.000000   \n",
       "59           0.768116           0.405797         0.680952        0.196216   \n",
       "60           0.449275           0.333333         0.552381        0.227898   \n",
       "61           0.637681           0.420290         0.676190        0.222029   \n",
       "62           0.913043           0.782609         0.880952        0.069988   \n",
       "63           0.913043           0.811594         0.847619        0.045880   \n",
       "64           0.913043           0.811594         0.904762        0.071718   \n",
       "65           0.913043           0.695652         0.814286        0.089181   \n",
       "66           0.333333           0.333333         0.333333        0.000000   \n",
       "67           0.333333           0.811594         0.490476        0.224636   \n",
       "68           0.956522           0.811594         0.904762        0.065362   \n",
       "69           0.971014           0.797101         0.919048        0.085531   \n",
       "70           0.333333           0.333333         0.509524        0.243925   \n",
       "71           0.942029           0.753623         0.671429        0.255873   \n",
       "72           0.333333           0.333333         0.333333        0.000000   \n",
       "73           0.333333           0.333333         0.333333        0.000000   \n",
       "74           0.898551           0.333333         0.519048        0.265479   \n",
       "75           0.333333           0.333333         0.333333        0.000000   \n",
       "76           0.913043           0.782609         0.895238        0.084282   \n",
       "77           0.898551           0.333333         0.700000        0.256957   \n",
       "78           0.333333           0.333333         0.523810        0.263702   \n",
       "79           0.333333           0.333333         0.333333        0.000000   \n",
       "80           0.333333           0.826087         0.680952        0.243999   \n",
       "81           0.333333           0.333333         0.504762        0.237332   \n",
       "82           0.333333           0.333333         0.333333        0.000000   \n",
       "83           0.942029           0.333333         0.533333        0.285901   \n",
       "84           0.333333           0.710145         0.633333        0.217245   \n",
       "85           0.333333           0.608696         0.623810        0.239174   \n",
       "86           0.913043           0.333333         0.742857        0.287504   \n",
       "87           0.855072           0.826087         0.852381        0.020124   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                33            0.847826            0.851064   \n",
       "1                29            0.891304            0.851064   \n",
       "2                12            0.978261            0.971631   \n",
       "3                 1            0.985507            0.964539   \n",
       "4                33            0.891304            0.851064   \n",
       "5                29            0.855072            0.851064   \n",
       "6                25            0.985507            0.914894   \n",
       "7                 5            0.978261            0.971631   \n",
       "8                 5            0.978261            0.957447   \n",
       "9                18            0.978261            0.957447   \n",
       "10                3            0.992754            0.964539   \n",
       "11                1            0.978261            0.964539   \n",
       "12               31            0.898551            0.843972   \n",
       "13               27            0.891304            0.851064   \n",
       "14               19            0.934783            0.964539   \n",
       "15                5            0.978261            0.964539   \n",
       "16                5            0.971014            0.964539   \n",
       "17                5            0.985507            0.971631   \n",
       "18                5            0.992754            0.964539   \n",
       "19               15            0.992754            0.964539   \n",
       "20                3            0.985507            0.964539   \n",
       "21                5            0.942029            0.964539   \n",
       "22               76            0.333333            0.333333   \n",
       "23               76            0.333333            0.333333   \n",
       "24               22            0.891304            0.964539   \n",
       "25               19            0.942029            0.978723   \n",
       "26               45            0.913043            0.865248   \n",
       "27               37            0.913043            0.879433   \n",
       "28               61            0.905797            0.248227   \n",
       "29               62            0.898551            0.163121   \n",
       "..              ...                 ...                 ...   \n",
       "58               76            0.333333            0.333333   \n",
       "59               53            0.898551            0.872340   \n",
       "60               63            0.898551            0.404255   \n",
       "61               55            0.949275            0.687943   \n",
       "62               23            0.992754            0.858156   \n",
       "63               33            0.884058            0.879433   \n",
       "64               15            0.978261            0.971631   \n",
       "65               42            0.898551            0.886525   \n",
       "66               76            0.333333            0.333333   \n",
       "67               72            0.333333            0.333333   \n",
       "68               15            0.985507            0.978723   \n",
       "69               12            0.956522            0.978723   \n",
       "70               69            0.876812            0.333333   \n",
       "71               56            0.333333            0.851064   \n",
       "72               76            0.333333            0.333333   \n",
       "73               76            0.333333            0.333333   \n",
       "74               68            0.333333            0.950355   \n",
       "75               76            0.333333            0.333333   \n",
       "76               19            0.978261            0.978723   \n",
       "77               51            0.905797            0.985816   \n",
       "78               65            0.862319            0.333333   \n",
       "79               76            0.333333            0.333333   \n",
       "80               53            0.862319            0.333333   \n",
       "81               71            0.905797            0.333333   \n",
       "82               76            0.333333            0.333333   \n",
       "83               64            0.333333            0.978723   \n",
       "84               58            0.891304            0.333333   \n",
       "85               59            0.884058            0.333333   \n",
       "86               49            0.956522            0.943262   \n",
       "87               31            0.876812            0.943262   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.914894          0.871261         0.030881  \n",
       "1             0.921986          0.888118         0.029041  \n",
       "2             1.000000          0.983297         0.012117  \n",
       "3             1.000000          0.983349         0.014557  \n",
       "4             0.914894          0.885754         0.026352  \n",
       "5             0.914894          0.873677         0.029191  \n",
       "6             0.957447          0.952616         0.029030  \n",
       "7             1.000000          0.983297         0.012117  \n",
       "8             1.000000          0.978569         0.017374  \n",
       "9             0.992908          0.976205         0.014550  \n",
       "10            1.000000          0.985764         0.015297  \n",
       "11            1.000000          0.980933         0.014600  \n",
       "12            0.914894          0.885805         0.030324  \n",
       "13            0.936170          0.892846         0.034762  \n",
       "14            0.992908          0.964076         0.023732  \n",
       "15            1.000000          0.980933         0.014600  \n",
       "16            1.000000          0.978518         0.015419  \n",
       "17            1.000000          0.985713         0.011582  \n",
       "18            1.000000          0.985764         0.015297  \n",
       "19            1.000000          0.985764         0.015297  \n",
       "20            1.000000          0.983349         0.014557  \n",
       "21            1.000000          0.968856         0.023863  \n",
       "22            0.333333          0.333333         0.000000  \n",
       "23            0.333333          0.333333         0.000000  \n",
       "24            0.964539          0.940127         0.034523  \n",
       "25            0.943262          0.954672         0.017015  \n",
       "26            0.687943          0.822078         0.096834  \n",
       "27            0.936170          0.909549         0.023294  \n",
       "28            0.645390          0.599805         0.270380  \n",
       "29            0.943262          0.668311         0.357690  \n",
       "..                 ...               ...              ...  \n",
       "58            0.333333          0.333333         0.000000  \n",
       "59            0.432624          0.734505         0.213730  \n",
       "60            0.333333          0.545380         0.251402  \n",
       "61            0.340426          0.659215         0.249391  \n",
       "62            0.978723          0.943211         0.060415  \n",
       "63            0.950355          0.904615         0.032398  \n",
       "64            0.964539          0.971477         0.005603  \n",
       "65            0.929078          0.904718         0.017911  \n",
       "66            0.333333          0.333333         0.000000  \n",
       "67            0.943262          0.536643         0.287523  \n",
       "68            1.000000          0.988077         0.008874  \n",
       "69            0.929078          0.954774         0.020305  \n",
       "70            0.333333          0.514493         0.256198  \n",
       "71            0.929078          0.704492         0.264374  \n",
       "72            0.333333          0.333333         0.000000  \n",
       "73            0.333333          0.333333         0.000000  \n",
       "74            0.333333          0.539007         0.290867  \n",
       "75            0.333333          0.333333         0.000000  \n",
       "76            0.900709          0.952564         0.036668  \n",
       "77            0.333333          0.741649         0.290565  \n",
       "78            0.333333          0.509662         0.249366  \n",
       "79            0.333333          0.333333         0.000000  \n",
       "80            0.978723          0.724792         0.280853  \n",
       "81            0.333333          0.524155         0.269862  \n",
       "82            0.333333          0.333333         0.000000  \n",
       "83            0.333333          0.548463         0.304240  \n",
       "84            0.957447          0.727361         0.279925  \n",
       "85            0.680851          0.632747         0.227391  \n",
       "86            0.333333          0.744372         0.290699  \n",
       "87            1.000000          0.940025         0.050344  \n",
       "\n",
       "[88 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas do modelo que o obteve a melhor média de acurácia entre os folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor média de acurácia entre os folds = 0.9880768835440437\n"
     ]
    }
   ],
   "source": [
    "print(\"Melhor média de acurácia entre os folds = \" + str(max(results['mean_train_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.074731</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>relu</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.065362</td>\n",
       "      <td>15</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988077</td>\n",
       "      <td>0.008874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "68       0.074731      0.016695         0.000474        0.000047   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "68             relu                     (7,)                     0.01   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "68  {'activation': 'relu', 'hidden_layer_sizes': (...           0.944444   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "68           0.956522           0.811594         0.904762        0.065362   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "68               15            0.985507            0.978723   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "68                 1.0          0.988077         0.008874  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results['mean_train_score']==max(results['mean_train_score'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características do melhor modelo que endereça a tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(7,), learning_rate='constant',\n",
       "       learning_rate_init=0.05, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos trabalhando com pouco dados, escolhemos o solver 'LBFGS', que converge mais rápido e trabalha com pouca memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
