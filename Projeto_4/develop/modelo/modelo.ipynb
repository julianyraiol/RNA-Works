{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto Prático 4\n",
    "\n",
    "**Universidade do Estado do Amazonas**  \n",
    "**Escola Superior de Tecnologia**  \n",
    "**Professora:** Elloá B. Guedes  \n",
    "**Alunos:** Juliany Raiol, Raí Soledade, Richardson Souza  \n",
    "**Disciplina:** Redes Neurais Artificiais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado de Máquina com tarefa de classificação aplicado no dataset  de variedades de trigo\n",
    "\n",
    "### Introdução\n",
    "\n",
    "Três variedades de trigo (Kama, Rosa e Canadian) possuem sementes muito parecidas,\n",
    "entretanto diferentes. Um grupo de pesquisadores poloneses coletou 70 amostras de cada\n",
    "tipo e, usando uma técnica particular de raio-X, coletou medidas geométricas destas\n",
    "sementes, a citar: área, perímetro, compactude, comprimento, largura, coeficiente de\n",
    "assimetria e comprimento do sulco da semente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos utilizados no projeto\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Area\", \"Perimeter\", \"Compactness\", \"Length\", \"Width\", \"Asymmetry\", \"Groove\", \"Seed\"]\n",
    "\n",
    "df = pd.read_csv('../../data/seeds_dataset.txt', delim_whitespace=True, names = names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = atributos preditores, y = atributo alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Seed', axis=1)\n",
    "y = df['Seed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição dos parâmetros de taxa de aprendizado, neurônios na camada de entrada e saída, funções de ativação e o alfa da regra da pirâmide geométrica utilizada para calcular a quantidade de neurônios nas camadas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate  = [0.01, 0.05]\n",
    "alpha = [0.5, 2, 3]\n",
    "\n",
    "neuron_out = 2\n",
    "neuron_ini = 7\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo da quantidade de neurônios nas camadas ocultas utilizando a regra da pirâmide geométrica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de neurônios nas camadas ocultas a serem testadas respectivamente:  [1, 7, 11]\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "for a in alpha:\n",
    "    n.append(int( a * np.sqrt((neuron_ini*neuron_out))))\n",
    "print(\"Quantidade de neurônios nas camadas ocultas a serem testadas respectivamente: \", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetro que define uma série de combinações de neurônios distribuídos em 1 ou 2 camadas, de acordo com a quantidade de neurônios calculada anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = [(1,), (7,),(1,6),(2,5),(3,4), (11,),(1,10),(2,9),(3,8),(4,7),(5,6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição dos parâmetros para inicialização dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict([\n",
    "                ('hidden_layer_sizes', hidden_layer),\n",
    "                ('learning_rate_init', rate),\n",
    "                ('activation', activation_functions)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento das redes neurais. O solver escolhido foi o LBFGS pois ele é um solver que se comporta melhor com datasets com poucos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'hidden_layer_sizes': [(1,), (7,), (1, 6), (2, 5), (3, 4), (11,), (1, 10), (2, 9), (3, 8), (4, 7), (5, 6)], 'learning_rate_init': [0.01, 0.05], 'activation': ['identity', 'logistic', 'tanh', 'relu']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(MLPClassifier(solver='lbfgs'), parameters, iid=True, cv = 3, return_train_score=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listagem de todas as redes neurais geradas pelo GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067011</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>3.734649e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.065013</td>\n",
       "      <td>30</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.876041</td>\n",
       "      <td>0.027502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051595</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>8.477188e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.047081</td>\n",
       "      <td>30</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.888169</td>\n",
       "      <td>0.027073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.018640</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>1.033942e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.068217</td>\n",
       "      <td>1</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976102</td>\n",
       "      <td>0.016901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051298</td>\n",
       "      <td>0.017681</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>2.751391e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.055960</td>\n",
       "      <td>7</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.014557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076147</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>7.590386e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>0.047936</td>\n",
       "      <td>28</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.921986</td>\n",
       "      <td>0.880872</td>\n",
       "      <td>0.030037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.081383</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>5.018294e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.071161</td>\n",
       "      <td>33</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.843972</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.880974</td>\n",
       "      <td>0.029036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.076412</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>2.944982e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.099202</td>\n",
       "      <td>17</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.944753</td>\n",
       "      <td>0.049418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.071808</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>1.150519e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.109205</td>\n",
       "      <td>17</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.973790</td>\n",
       "      <td>0.014609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.060940</td>\n",
       "      <td>0.015710</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>1.007081e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>4</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.014557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.070131</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>3.030408e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.065692</td>\n",
       "      <td>11</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954877</td>\n",
       "      <td>0.044905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.061311</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>3.274610e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.065347</td>\n",
       "      <td>7</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983297</td>\n",
       "      <td>0.012117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.064017</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>9.387222e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.071899</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988077</td>\n",
       "      <td>0.008874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>1.441901e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.064952</td>\n",
       "      <td>35</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.843972</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.878559</td>\n",
       "      <td>0.028980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.073275</td>\n",
       "      <td>0.007535</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>7.971884e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.070561</td>\n",
       "      <td>34</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.888169</td>\n",
       "      <td>0.027073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.076943</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>1.411622e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.085857</td>\n",
       "      <td>19</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.976257</td>\n",
       "      <td>0.013301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.075906</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>6.464735e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.072291</td>\n",
       "      <td>13</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.980985</td>\n",
       "      <td>0.012015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.074477</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>1.500628e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.072125</td>\n",
       "      <td>9</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976051</td>\n",
       "      <td>0.018023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.074835</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>6.254671e-06</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.102398</td>\n",
       "      <td>13</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980933</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.065804</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>1.452115e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.061556</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980985</td>\n",
       "      <td>0.017664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.075124</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>2.068005e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.102398</td>\n",
       "      <td>13</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985661</td>\n",
       "      <td>0.010141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.075933</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>3.333998e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.909524</td>\n",
       "      <td>0.069365</td>\n",
       "      <td>10</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.014557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.063795</td>\n",
       "      <td>0.015466</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>1.432232e-05</td>\n",
       "      <td>identity</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>4</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976154</td>\n",
       "      <td>0.017748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>1.663244e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.015247</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>5.136923e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.142950</td>\n",
       "      <td>77</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.442080</td>\n",
       "      <td>0.163924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.071516</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>8.351081e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.061810</td>\n",
       "      <td>25</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968959</td>\n",
       "      <td>0.022093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.066497</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>2.379439e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.048244</td>\n",
       "      <td>13</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>0.011582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.084596</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>6.768737e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.083045</td>\n",
       "      <td>44</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.695035</td>\n",
       "      <td>0.709220</td>\n",
       "      <td>0.750694</td>\n",
       "      <td>0.068927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.030578</td>\n",
       "      <td>0.038573</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>3.654023e-06</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.190184</td>\n",
       "      <td>79</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.412889</td>\n",
       "      <td>0.200169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>1.273749e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.163958</td>\n",
       "      <td>46</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>0.645390</td>\n",
       "      <td>0.717751</td>\n",
       "      <td>0.184969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.080707</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>2.265214e-05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.110942</td>\n",
       "      <td>41</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.836366</td>\n",
       "      <td>0.105860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.033887</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>4.299518e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.309850</td>\n",
       "      <td>61</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.541063</td>\n",
       "      <td>0.293774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.062148</td>\n",
       "      <td>0.041243</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>1.867088e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.256526</td>\n",
       "      <td>46</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.710967</td>\n",
       "      <td>0.267247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.060003</td>\n",
       "      <td>0.039390</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>4.451899e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.247932</td>\n",
       "      <td>49</td>\n",
       "      <td>0.398551</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.735687</td>\n",
       "      <td>0.239811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.059435</td>\n",
       "      <td>0.039263</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.256959</td>\n",
       "      <td>49</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.713948</td>\n",
       "      <td>0.271013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.061774</td>\n",
       "      <td>0.038164</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>1.852144e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.248763</td>\n",
       "      <td>54</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.739953</td>\n",
       "      <td>0.287582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.062022</td>\n",
       "      <td>0.039331</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>1.997917e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.252802</td>\n",
       "      <td>51</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.770686</td>\n",
       "      <td>0.309377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.034254</td>\n",
       "      <td>0.038156</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>2.553961e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.538095</td>\n",
       "      <td>0.283480</td>\n",
       "      <td>64</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.538647</td>\n",
       "      <td>0.290358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.061055</td>\n",
       "      <td>0.038589</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>3.754620e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.238567</td>\n",
       "      <td>58</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.739953</td>\n",
       "      <td>0.290367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>3.893359e-07</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>3.907932e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.034318</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>1.755613e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.219681</td>\n",
       "      <td>60</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707729</td>\n",
       "      <td>0.278292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.057456</td>\n",
       "      <td>0.013768</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>8.045229e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>4</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980985</td>\n",
       "      <td>0.017664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.029970</td>\n",
       "      <td>0.036964</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>2.306083e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.480952</td>\n",
       "      <td>0.211022</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.534279</td>\n",
       "      <td>0.284180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.021537</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>3.643638e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.102107</td>\n",
       "      <td>78</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.449173</td>\n",
       "      <td>0.163821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.031466</td>\n",
       "      <td>0.038156</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>1.505922e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.272286</td>\n",
       "      <td>67</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.843972</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.503546</td>\n",
       "      <td>0.240717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.031884</td>\n",
       "      <td>0.039613</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>2.359769e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.270295</td>\n",
       "      <td>66</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.526570</td>\n",
       "      <td>0.273278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.029574</td>\n",
       "      <td>0.035958</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>3.896424e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.504762</td>\n",
       "      <td>0.237332</td>\n",
       "      <td>74</td>\n",
       "      <td>0.905797</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.524155</td>\n",
       "      <td>0.269862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.054513</td>\n",
       "      <td>0.035171</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>1.637411e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.266102</td>\n",
       "      <td>51</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.737589</td>\n",
       "      <td>0.286569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.048251</td>\n",
       "      <td>0.030624</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>1.938779e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>0.290388</td>\n",
       "      <td>42</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.763491</td>\n",
       "      <td>0.304220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.027683</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>1.739675e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.303258</td>\n",
       "      <td>62</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.545894</td>\n",
       "      <td>0.300606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.031473</td>\n",
       "      <td>0.038629</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>1.673956e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.272286</td>\n",
       "      <td>67</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.508274</td>\n",
       "      <td>0.247404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.030976</td>\n",
       "      <td>0.038727</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>1.793306e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.272286</td>\n",
       "      <td>67</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.836879</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.501182</td>\n",
       "      <td>0.237374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.032302</td>\n",
       "      <td>0.039789</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>4.723015e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.285901</td>\n",
       "      <td>65</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.543735</td>\n",
       "      <td>0.297553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>4.057508e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>6.091193e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.033310</td>\n",
       "      <td>0.039922</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>7.150818e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.250517</td>\n",
       "      <td>72</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.266446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.032491</td>\n",
       "      <td>0.039322</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>8.948002e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.272286</td>\n",
       "      <td>67</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.513002</td>\n",
       "      <td>0.254090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.072735</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>2.628234e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.041789</td>\n",
       "      <td>24</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>0.909189</td>\n",
       "      <td>0.045965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.082337</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>1.314982e-05</td>\n",
       "      <td>relu</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.096236</td>\n",
       "      <td>11</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.964128</td>\n",
       "      <td>0.017878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.062468</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>2.439182e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>0.106184</td>\n",
       "      <td>42</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.907801</td>\n",
       "      <td>0.819406</td>\n",
       "      <td>0.099209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.067011      0.003329         0.000461    3.734649e-05   \n",
       "1        0.051595      0.011996         0.000366    8.477188e-06   \n",
       "2        0.055197      0.018640         0.000388    1.033942e-05   \n",
       "3        0.051298      0.017681         0.000366    2.751391e-05   \n",
       "4        0.076147      0.000718         0.000364    7.590386e-06   \n",
       "5        0.081383      0.004074         0.000434    5.018294e-05   \n",
       "6        0.076412      0.002141         0.000384    2.944982e-05   \n",
       "7        0.071808      0.000254         0.000358    1.150519e-05   \n",
       "8        0.060940      0.015710         0.000353    1.007081e-05   \n",
       "9        0.070131      0.002607         0.000359    3.030408e-06   \n",
       "10       0.061311      0.005104         0.000385    3.274610e-05   \n",
       "11       0.064017      0.000469         0.000353    9.387222e-06   \n",
       "12       0.077820      0.000352         0.000387    1.441901e-05   \n",
       "13       0.073275      0.007535         0.000384    7.971884e-06   \n",
       "14       0.076943      0.001334         0.000366    1.411622e-05   \n",
       "15       0.075906      0.000497         0.000448    6.464735e-05   \n",
       "16       0.074477      0.000199         0.000378    1.500628e-05   \n",
       "17       0.074835      0.000608         0.000378    6.254671e-06   \n",
       "18       0.065804      0.011802         0.000363    1.452115e-05   \n",
       "19       0.075124      0.000264         0.000415    2.068005e-05   \n",
       "20       0.075933      0.000782         0.000417    3.333998e-05   \n",
       "21       0.063795      0.015466         0.000358    1.432232e-05   \n",
       "22       0.004996      0.001447         0.000351    1.663244e-06   \n",
       "23       0.015247      0.016347         0.000354    5.136923e-06   \n",
       "24       0.071516      0.001084         0.000361    8.351081e-06   \n",
       "25       0.066497      0.001950         0.000367    2.379439e-05   \n",
       "26       0.084596      0.000288         0.000383    6.768737e-06   \n",
       "27       0.030578      0.038573         0.000376    3.654023e-06   \n",
       "28       0.084373      0.001927         0.000377    1.273749e-05   \n",
       "29       0.080707      0.000319         0.000380    2.265214e-05   \n",
       "..            ...           ...              ...             ...   \n",
       "58       0.033887      0.041616         0.000424    4.299518e-05   \n",
       "59       0.062148      0.041243         0.000389    1.867088e-05   \n",
       "60       0.060003      0.039390         0.000373    4.451899e-06   \n",
       "61       0.059435      0.039263         0.000368    1.946680e-07   \n",
       "62       0.061774      0.038164         0.000384    1.852144e-05   \n",
       "63       0.062022      0.039331         0.000373    1.997917e-06   \n",
       "64       0.034254      0.038156         0.000389    2.553961e-05   \n",
       "65       0.061055      0.038589         0.000374    3.754620e-06   \n",
       "66       0.003354      0.000129         0.000348    3.893359e-07   \n",
       "67       0.003719      0.000144         0.000351    3.907932e-06   \n",
       "68       0.034318      0.021717         0.000358    1.755613e-06   \n",
       "69       0.057456      0.013768         0.000350    8.045229e-06   \n",
       "70       0.029970      0.036964         0.000372    2.306083e-06   \n",
       "71       0.021537      0.024756         0.000374    3.643638e-06   \n",
       "72       0.031466      0.038156         0.000384    1.505922e-05   \n",
       "73       0.031884      0.039613         0.000386    2.359769e-05   \n",
       "74       0.029574      0.035958         0.000381    3.896424e-05   \n",
       "75       0.054513      0.035171         0.000374    1.637411e-05   \n",
       "76       0.048251      0.030624         0.000368    1.938779e-05   \n",
       "77       0.027683      0.030551         0.000362    1.739675e-05   \n",
       "78       0.031473      0.038629         0.000390    1.673956e-05   \n",
       "79       0.030976      0.038727         0.000389    1.793306e-05   \n",
       "80       0.032302      0.039789         0.000455    4.723015e-05   \n",
       "81       0.004715      0.000142         0.000430    4.057508e-05   \n",
       "82       0.005525      0.001229         0.000830    6.091193e-04   \n",
       "83       0.033310      0.039922         0.000528    7.150818e-05   \n",
       "84       0.032491      0.039322         0.000495    8.948002e-05   \n",
       "85       0.072735      0.015429         0.000419    2.628234e-05   \n",
       "86       0.082337      0.000900         0.000378    1.314982e-05   \n",
       "87       0.062468      0.002843         0.000360    2.439182e-06   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "0          identity                     (1,)                     0.01   \n",
       "1          identity                     (1,)                     0.05   \n",
       "2          identity                     (7,)                     0.01   \n",
       "3          identity                     (7,)                     0.05   \n",
       "4          identity                   (1, 6)                     0.01   \n",
       "5          identity                   (1, 6)                     0.05   \n",
       "6          identity                   (2, 5)                     0.01   \n",
       "7          identity                   (2, 5)                     0.05   \n",
       "8          identity                   (3, 4)                     0.01   \n",
       "9          identity                   (3, 4)                     0.05   \n",
       "10         identity                    (11,)                     0.01   \n",
       "11         identity                    (11,)                     0.05   \n",
       "12         identity                  (1, 10)                     0.01   \n",
       "13         identity                  (1, 10)                     0.05   \n",
       "14         identity                   (2, 9)                     0.01   \n",
       "15         identity                   (2, 9)                     0.05   \n",
       "16         identity                   (3, 8)                     0.01   \n",
       "17         identity                   (3, 8)                     0.05   \n",
       "18         identity                   (4, 7)                     0.01   \n",
       "19         identity                   (4, 7)                     0.05   \n",
       "20         identity                   (5, 6)                     0.01   \n",
       "21         identity                   (5, 6)                     0.05   \n",
       "22         logistic                     (1,)                     0.01   \n",
       "23         logistic                     (1,)                     0.05   \n",
       "24         logistic                     (7,)                     0.01   \n",
       "25         logistic                     (7,)                     0.05   \n",
       "26         logistic                   (1, 6)                     0.01   \n",
       "27         logistic                   (1, 6)                     0.05   \n",
       "28         logistic                   (2, 5)                     0.01   \n",
       "29         logistic                   (2, 5)                     0.05   \n",
       "..              ...                      ...                      ...   \n",
       "58             tanh                   (2, 9)                     0.01   \n",
       "59             tanh                   (2, 9)                     0.05   \n",
       "60             tanh                   (3, 8)                     0.01   \n",
       "61             tanh                   (3, 8)                     0.05   \n",
       "62             tanh                   (4, 7)                     0.01   \n",
       "63             tanh                   (4, 7)                     0.05   \n",
       "64             tanh                   (5, 6)                     0.01   \n",
       "65             tanh                   (5, 6)                     0.05   \n",
       "66             relu                     (1,)                     0.01   \n",
       "67             relu                     (1,)                     0.05   \n",
       "68             relu                     (7,)                     0.01   \n",
       "69             relu                     (7,)                     0.05   \n",
       "70             relu                   (1, 6)                     0.01   \n",
       "71             relu                   (1, 6)                     0.05   \n",
       "72             relu                   (2, 5)                     0.01   \n",
       "73             relu                   (2, 5)                     0.05   \n",
       "74             relu                   (3, 4)                     0.01   \n",
       "75             relu                   (3, 4)                     0.05   \n",
       "76             relu                    (11,)                     0.01   \n",
       "77             relu                    (11,)                     0.05   \n",
       "78             relu                  (1, 10)                     0.01   \n",
       "79             relu                  (1, 10)                     0.05   \n",
       "80             relu                   (2, 9)                     0.01   \n",
       "81             relu                   (2, 9)                     0.05   \n",
       "82             relu                   (3, 8)                     0.01   \n",
       "83             relu                   (3, 8)                     0.05   \n",
       "84             relu                   (4, 7)                     0.01   \n",
       "85             relu                   (4, 7)                     0.05   \n",
       "86             relu                   (5, 6)                     0.01   \n",
       "87             relu                   (5, 6)                     0.05   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'activation': 'identity', 'hidden_layer_sizes...           0.847222   \n",
       "1   {'activation': 'identity', 'hidden_layer_sizes...           0.861111   \n",
       "2   {'activation': 'identity', 'hidden_layer_sizes...           0.986111   \n",
       "3   {'activation': 'identity', 'hidden_layer_sizes...           0.944444   \n",
       "4   {'activation': 'identity', 'hidden_layer_sizes...           0.875000   \n",
       "5   {'activation': 'identity', 'hidden_layer_sizes...           0.861111   \n",
       "6   {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "7   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "8   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "9   {'activation': 'identity', 'hidden_layer_sizes...           0.986111   \n",
       "10  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "11  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "12  {'activation': 'identity', 'hidden_layer_sizes...           0.847222   \n",
       "13  {'activation': 'identity', 'hidden_layer_sizes...           0.847222   \n",
       "14  {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "15  {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "16  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "17  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "18  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "19  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "20  {'activation': 'identity', 'hidden_layer_sizes...           0.944444   \n",
       "21  {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "22  {'activation': 'logistic', 'hidden_layer_sizes...           0.333333   \n",
       "23  {'activation': 'logistic', 'hidden_layer_sizes...           0.333333   \n",
       "24  {'activation': 'logistic', 'hidden_layer_sizes...           0.930556   \n",
       "25  {'activation': 'logistic', 'hidden_layer_sizes...           0.958333   \n",
       "26  {'activation': 'logistic', 'hidden_layer_sizes...           0.819444   \n",
       "27  {'activation': 'logistic', 'hidden_layer_sizes...           0.180556   \n",
       "28  {'activation': 'logistic', 'hidden_layer_sizes...           0.541667   \n",
       "29  {'activation': 'logistic', 'hidden_layer_sizes...           0.902778   \n",
       "..                                                ...                ...   \n",
       "58  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.986111   \n",
       "59  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.875000   \n",
       "60  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.347222   \n",
       "61  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "62  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "63  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "64  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.930556   \n",
       "65  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "66  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "67  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "68  {'activation': 'relu', 'hidden_layer_sizes': (...           0.750000   \n",
       "69  {'activation': 'relu', 'hidden_layer_sizes': (...           0.972222   \n",
       "70  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "71  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "72  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "73  {'activation': 'relu', 'hidden_layer_sizes': (...           0.902778   \n",
       "74  {'activation': 'relu', 'hidden_layer_sizes': (...           0.833333   \n",
       "75  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "76  {'activation': 'relu', 'hidden_layer_sizes': (...           0.972222   \n",
       "77  {'activation': 'relu', 'hidden_layer_sizes': (...           0.972222   \n",
       "78  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "79  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "80  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "81  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "82  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "83  {'activation': 'relu', 'hidden_layer_sizes': (...           0.861111   \n",
       "84  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "85  {'activation': 'relu', 'hidden_layer_sizes': (...           0.861111   \n",
       "86  {'activation': 'relu', 'hidden_layer_sizes': (...           0.958333   \n",
       "87  {'activation': 'relu', 'hidden_layer_sizes': (...           0.888889   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.942029           0.782609         0.857143        0.065013   \n",
       "1            0.913043           0.797101         0.857143        0.047081   \n",
       "2            0.985507           0.840580         0.938095        0.068217   \n",
       "3            0.971014           0.840580         0.919048        0.055960   \n",
       "4            0.913043           0.797101         0.861905        0.047936   \n",
       "5            0.927536           0.753623         0.847619        0.071161   \n",
       "6            0.971014           0.753623         0.895238        0.099202   \n",
       "7            0.971014           0.739130         0.895238        0.109205   \n",
       "8            0.971014           0.826087         0.923810        0.068363   \n",
       "9            0.898551           0.826087         0.904762        0.065692   \n",
       "10           0.956522           0.826087         0.919048        0.065347   \n",
       "11           0.985507           0.826087         0.928571        0.071899   \n",
       "12           0.913043           0.753623         0.838095        0.064952   \n",
       "13           0.927536           0.753623         0.842857        0.070561   \n",
       "14           0.942029           0.768116         0.890476        0.085857   \n",
       "15           0.942029           0.797101         0.900000        0.072291   \n",
       "16           0.956522           0.811594         0.914286        0.072125   \n",
       "17           0.971014           0.753623         0.900000        0.102398   \n",
       "18           0.971014           0.840580         0.928571        0.061556   \n",
       "19           0.971014           0.753623         0.900000        0.102398   \n",
       "20           0.971014           0.811594         0.909524        0.069365   \n",
       "21           0.985507           0.826087         0.923810        0.069261   \n",
       "22           0.333333           0.333333         0.333333        0.000000   \n",
       "23           0.637681           0.333333         0.433333        0.142950   \n",
       "24           0.884058           0.782609         0.866667        0.061810   \n",
       "25           0.898551           0.840580         0.900000        0.048244   \n",
       "26           0.637681           0.652174         0.704762        0.083045   \n",
       "27           0.637681           0.333333         0.380952        0.190184   \n",
       "28           0.927536           0.637681         0.700000        0.163958   \n",
       "29           0.637681           0.724638         0.757143        0.110942   \n",
       "..                ...                ...              ...             ...   \n",
       "58           0.333333           0.333333         0.557143        0.309850   \n",
       "59           0.884058           0.333333         0.700000        0.256526   \n",
       "60           0.913043           0.811594         0.685714        0.247932   \n",
       "61           0.913043           0.826087         0.685714        0.256959   \n",
       "62           0.884058           0.826087         0.676190        0.248763   \n",
       "63           0.898551           0.826087         0.680952        0.252802   \n",
       "64           0.333333           0.333333         0.538095        0.283480   \n",
       "65           0.884058           0.768116         0.657143        0.238567   \n",
       "66           0.333333           0.333333         0.333333        0.000000   \n",
       "67           0.333333           0.333333         0.333333        0.000000   \n",
       "68           0.333333           0.840580         0.642857        0.219681   \n",
       "69           0.971014           0.826087         0.923810        0.068363   \n",
       "70           0.333333           0.782609         0.480952        0.211022   \n",
       "71           0.333333           0.550725         0.404762        0.102107   \n",
       "72           0.913043           0.333333         0.523810        0.272286   \n",
       "73           0.333333           0.333333         0.528571        0.270295   \n",
       "74           0.333333           0.333333         0.504762        0.237332   \n",
       "75           0.971014           0.753623         0.680952        0.266102   \n",
       "76           0.927536           0.333333         0.747619        0.290388   \n",
       "77           0.333333           0.333333         0.552381        0.303258   \n",
       "78           0.913043           0.333333         0.523810        0.272286   \n",
       "79           0.913043           0.333333         0.523810        0.272286   \n",
       "80           0.942029           0.333333         0.533333        0.285901   \n",
       "81           0.333333           0.333333         0.333333        0.000000   \n",
       "82           0.333333           0.333333         0.333333        0.000000   \n",
       "83           0.333333           0.333333         0.514286        0.250517   \n",
       "84           0.913043           0.333333         0.523810        0.272286   \n",
       "85           0.927536           0.826087         0.871429        0.041789   \n",
       "86           0.985507           0.768116         0.904762        0.096236   \n",
       "87           0.637681           0.710145         0.747619        0.106184   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                30            0.855072            0.858156   \n",
       "1                30            0.898551            0.851064   \n",
       "2                 1            0.963768            0.964539   \n",
       "3                 7            0.985507            0.964539   \n",
       "4                28            0.869565            0.851064   \n",
       "5                33            0.884058            0.843972   \n",
       "6                17            0.876812            0.964539   \n",
       "7                17            0.971014            0.957447   \n",
       "8                 4            0.985507            0.964539   \n",
       "9                11            0.971014            0.893617   \n",
       "10                7            0.978261            0.971631   \n",
       "11                2            0.985507            0.978723   \n",
       "12               35            0.876812            0.843972   \n",
       "13               34            0.898551            0.851064   \n",
       "14               19            0.985507            0.957447   \n",
       "15               13            0.985507            0.964539   \n",
       "16                9            0.956522            0.971631   \n",
       "17               13            0.978261            0.964539   \n",
       "18                2            0.985507            0.957447   \n",
       "19               13            0.978261            0.978723   \n",
       "20               10            0.985507            0.964539   \n",
       "21                4            0.971014            0.957447   \n",
       "22               81            0.333333            0.333333   \n",
       "23               77            0.333333            0.673759   \n",
       "24               25            0.956522            0.950355   \n",
       "25               13            0.985507            0.971631   \n",
       "26               44            0.847826            0.695035   \n",
       "27               79            0.217391            0.687943   \n",
       "28               46            0.536232            0.971631   \n",
       "29               41            0.927536            0.687943   \n",
       "..              ...                 ...                 ...   \n",
       "58               61            0.956522            0.333333   \n",
       "59               46            0.913043            0.886525   \n",
       "60               49            0.398551            0.872340   \n",
       "61               49            0.333333            0.865248   \n",
       "62               54            0.333333            0.936170   \n",
       "63               51            0.333333            0.978723   \n",
       "64               64            0.949275            0.333333   \n",
       "65               58            0.333333            0.893617   \n",
       "66               81            0.333333            0.333333   \n",
       "67               81            0.333333            0.333333   \n",
       "68               60            0.789855            0.333333   \n",
       "69                4            0.985507            0.957447   \n",
       "70               76            0.333333            0.333333   \n",
       "71               78            0.333333            0.333333   \n",
       "72               67            0.333333            0.843972   \n",
       "73               66            0.913043            0.333333   \n",
       "74               74            0.905797            0.333333   \n",
       "75               51            0.333333            0.964539   \n",
       "76               42            0.985507            0.971631   \n",
       "77               62            0.971014            0.333333   \n",
       "78               67            0.333333            0.858156   \n",
       "79               67            0.333333            0.836879   \n",
       "80               65            0.333333            0.964539   \n",
       "81               81            0.333333            0.333333   \n",
       "82               81            0.333333            0.333333   \n",
       "83               72            0.898551            0.333333   \n",
       "84               67            0.333333            0.872340   \n",
       "85               24            0.862319            0.893617   \n",
       "86               11            0.942029            0.964539   \n",
       "87               42            0.869565            0.680851   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.914894          0.876041         0.027502  \n",
       "1             0.914894          0.888169         0.027073  \n",
       "2             1.000000          0.976102         0.016901  \n",
       "3             1.000000          0.983349         0.014557  \n",
       "4             0.921986          0.880872         0.030037  \n",
       "5             0.914894          0.880974         0.029036  \n",
       "6             0.992908          0.944753         0.049418  \n",
       "7             0.992908          0.973790         0.014609  \n",
       "8             1.000000          0.983349         0.014557  \n",
       "9             1.000000          0.954877         0.044905  \n",
       "10            1.000000          0.983297         0.012117  \n",
       "11            1.000000          0.988077         0.008874  \n",
       "12            0.914894          0.878559         0.028980  \n",
       "13            0.914894          0.888169         0.027073  \n",
       "14            0.985816          0.976257         0.013301  \n",
       "15            0.992908          0.980985         0.012015  \n",
       "16            1.000000          0.976051         0.018023  \n",
       "17            1.000000          0.980933         0.014600  \n",
       "18            1.000000          0.980985         0.017664  \n",
       "19            1.000000          0.985661         0.010141  \n",
       "20            1.000000          0.983349         0.014557  \n",
       "21            1.000000          0.976154         0.017748  \n",
       "22            0.333333          0.333333         0.000000  \n",
       "23            0.319149          0.442080         0.163924  \n",
       "24            1.000000          0.968959         0.022093  \n",
       "25            1.000000          0.985713         0.011582  \n",
       "26            0.709220          0.750694         0.068927  \n",
       "27            0.333333          0.412889         0.200169  \n",
       "28            0.645390          0.717751         0.184969  \n",
       "29            0.893617          0.836366         0.105860  \n",
       "..                 ...               ...              ...  \n",
       "58            0.333333          0.541063         0.293774  \n",
       "59            0.333333          0.710967         0.267247  \n",
       "60            0.936170          0.735687         0.239811  \n",
       "61            0.943262          0.713948         0.271013  \n",
       "62            0.950355          0.739953         0.287582  \n",
       "63            1.000000          0.770686         0.309377  \n",
       "64            0.333333          0.538647         0.290358  \n",
       "65            0.992908          0.739953         0.290367  \n",
       "66            0.333333          0.333333         0.000000  \n",
       "67            0.333333          0.333333         0.000000  \n",
       "68            1.000000          0.707729         0.278292  \n",
       "69            1.000000          0.980985         0.017664  \n",
       "70            0.936170          0.534279         0.284180  \n",
       "71            0.680851          0.449173         0.163821  \n",
       "72            0.333333          0.503546         0.240717  \n",
       "73            0.333333          0.526570         0.273278  \n",
       "74            0.333333          0.524155         0.269862  \n",
       "75            0.914894          0.737589         0.286569  \n",
       "76            0.333333          0.763491         0.304220  \n",
       "77            0.333333          0.545894         0.300606  \n",
       "78            0.333333          0.508274         0.247404  \n",
       "79            0.333333          0.501182         0.237374  \n",
       "80            0.333333          0.543735         0.297553  \n",
       "81            0.333333          0.333333         0.000000  \n",
       "82            0.333333          0.333333         0.000000  \n",
       "83            0.333333          0.521739         0.266446  \n",
       "84            0.333333          0.513002         0.254090  \n",
       "85            0.971631          0.909189         0.045965  \n",
       "86            0.985816          0.964128         0.017878  \n",
       "87            0.907801          0.819406         0.099209  \n",
       "\n",
       "[88 rows x 19 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas do modelo que o obteve a melhor média de acurácia entre os folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor média entre os folds = 0.9880768835440437\n"
     ]
    }
   ],
   "source": [
    "print(\"Melhor média de acurácia entre os folds = \" + str(max(results['mean_train_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.064017</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>identity</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.071899</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988077</td>\n",
       "      <td>0.008874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11       0.064017      0.000469         0.000353        0.000009   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "11         identity                    (11,)                     0.05   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "11  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "11           0.985507           0.826087         0.928571        0.071899   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "11                2            0.985507            0.978723   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "11                 1.0          0.988077         0.008874  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results['mean_train_score']==max(results['mean_train_score'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características do melhor modelo que endereça a tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(7,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = clf.best_estimator_.predict(X)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904762"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
