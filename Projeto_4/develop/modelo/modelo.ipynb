{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto Prático 4\n",
    "\n",
    "**Universidade do Estado do Amazonas**  \n",
    "**Escola Superior de Tecnologia**  \n",
    "**Professora:** Elloá B. Guedes  \n",
    "**Alunos:** Juliany Raiol, Raí Soledade, Richardson Souza  \n",
    "**Disciplina:** Redes Neurais Artificiais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado de Máquina com tarefa de classificação aplicado no dataset  de variedades de trigo\n",
    "\n",
    "### Introdução\n",
    "\n",
    "Três variedades de trigo (Kama, Rosa e Canadian) possuem sementes muito parecidas,\n",
    "entretanto diferentes. Um grupo de pesquisadores poloneses coletou 70 amostras de cada\n",
    "tipo e, usando uma técnica particular de raio-X, coletou medidas geométricas destas\n",
    "sementes, a citar: área, perímetro, compactude, comprimento, largura, coeficiente de\n",
    "assimetria e comprimento do sulco da semente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# Módulos utilizados no projeto\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Area\", \"Perimeter\", \"Compactness\", \"Length\", \"Width\", \"Asymmetry\", \"Groove\", \"Seed\"]\n",
    "\n",
    "df = pd.read_csv('../../data/seeds_dataset.txt', delim_whitespace=True, names = names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = atributos preditores, y = atributo alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Seed', axis=1)\n",
    "y = df['Seed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição dos parâmetros de taxa de aprendizado, neurônios na camada de entrada e saída, funções de ativação e o alfa da regra da pirâmide geométrica utilizada para calcular a quantidade de neurônios nas camadas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate  = [0.01, 0.05]\n",
    "alpha = [0.5, 2, 3]\n",
    "\n",
    "neuron_out = 2\n",
    "neuron_ini = 7\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo da quantidade de neurônios nas camadas ocultas utilizando a regra da pirâmide geométrica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de neurônios nas camadas ocultas a serem testadas respectivamente:  [1, 7, 11]\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "for a in alpha:\n",
    "    n.append(int( a * np.sqrt((neuron_ini*neuron_out))))\n",
    "print(\"Quantidade de neurônios nas camadas ocultas a serem testadas respectivamente: \", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetro que define uma série de combinações de neurônios distribuídos em 1 ou 2 camadas, de acordo com a quantidade de neurônios calculada anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = [(1,), (7,),(1,6),(2,5),(3,4), (11,),(1,10),(2,9),(3,8),(4,7),(5,6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição dos parâmetros para inicialização dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict([\n",
    "                ('hidden_layer_sizes', hidden_layer),\n",
    "                ('learning_rate_init', rate),\n",
    "                ('activation', activation_functions)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento das redes neurais. O solver escolhido foi o LBFGS pois ele é um solver que se comporta melhor com datasets com poucos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=None,\n",
       "       param_grid={'hidden_layer_sizes': [(1,), (7,), (1, 6), (2, 5), (3, 4), (11,), (1, 10), (2, 9), (3, 8), (4, 7), (5, 6)], 'learning_rate_init': [0.01, 0.05], 'activation': ['identity', 'logistic', 'tanh', 'relu']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(MLPClassifier(solver='lbfgs'), parameters, iid=True, cv = 3, return_train_score=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listagem de todas as redes neurais geradas pelo GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067127</td>\n",
       "      <td>0.023680</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.069790</td>\n",
       "      <td>30</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.871210</td>\n",
       "      <td>0.031712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058989</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.069790</td>\n",
       "      <td>30</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.885754</td>\n",
       "      <td>0.026352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.051481</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>identity</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.081977</td>\n",
       "      <td>9</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.014557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048233</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>identity</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.058577</td>\n",
       "      <td>3</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980933</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057886</td>\n",
       "      <td>0.014541</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.067576</td>\n",
       "      <td>34</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.878508</td>\n",
       "      <td>0.026815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.067743</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.059454</td>\n",
       "      <td>26</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.883184</td>\n",
       "      <td>0.032496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.080654</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.058701</td>\n",
       "      <td>18</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935656</td>\n",
       "      <td>0.049555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.073303</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.073951</td>\n",
       "      <td>23</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964025</td>\n",
       "      <td>0.029585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.072371</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.082867</td>\n",
       "      <td>9</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.980985</td>\n",
       "      <td>0.012015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.061050</td>\n",
       "      <td>0.012812</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>3</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>0.011582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.061105</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>identity</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.085480</td>\n",
       "      <td>6</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980933</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.054143</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>identity</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.060959</td>\n",
       "      <td>3</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>0.011582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.076107</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.076625</td>\n",
       "      <td>30</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.885754</td>\n",
       "      <td>0.026352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.073388</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>identity</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.076625</td>\n",
       "      <td>30</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.885703</td>\n",
       "      <td>0.023192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.071367</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.082838</td>\n",
       "      <td>17</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>0.011582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.071353</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>identity</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.103627</td>\n",
       "      <td>25</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.978518</td>\n",
       "      <td>0.010178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.070807</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.909524</td>\n",
       "      <td>0.068510</td>\n",
       "      <td>11</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978518</td>\n",
       "      <td>0.015419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.070942</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>identity</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.085693</td>\n",
       "      <td>14</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.973790</td>\n",
       "      <td>0.014609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.068196</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>identity</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.105868</td>\n",
       "      <td>14</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976154</td>\n",
       "      <td>0.017748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.070639</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>identity</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.909524</td>\n",
       "      <td>0.088784</td>\n",
       "      <td>11</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980933</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.071261</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>identity</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.075170</td>\n",
       "      <td>6</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980933</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.073574</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>identity</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.065179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>0.011582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.041393</td>\n",
       "      <td>0.026982</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.283103</td>\n",
       "      <td>50</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.694676</td>\n",
       "      <td>0.292295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.026370</td>\n",
       "      <td>88</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.301932</td>\n",
       "      <td>0.044408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.056559</td>\n",
       "      <td>0.014107</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.097305</td>\n",
       "      <td>40</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.687943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859749</td>\n",
       "      <td>0.129336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.063974</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.080887</td>\n",
       "      <td>18</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>0.005793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.030395</td>\n",
       "      <td>0.035163</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.438095</td>\n",
       "      <td>0.145036</td>\n",
       "      <td>80</td>\n",
       "      <td>0.644928</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262411</td>\n",
       "      <td>0.413557</td>\n",
       "      <td>0.166146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.029712</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.405797</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.538095</td>\n",
       "      <td>0.235161</td>\n",
       "      <td>61</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.418440</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.542862</td>\n",
       "      <td>0.238681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.031180</td>\n",
       "      <td>0.033444</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.197408</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.900709</td>\n",
       "      <td>0.522459</td>\n",
       "      <td>0.267464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.069245</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.112933</td>\n",
       "      <td>45</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.602837</td>\n",
       "      <td>0.645390</td>\n",
       "      <td>0.713177</td>\n",
       "      <td>0.127147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.060108</td>\n",
       "      <td>0.039002</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.230765</td>\n",
       "      <td>52</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.725049</td>\n",
       "      <td>0.277585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.032669</td>\n",
       "      <td>0.037862</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.509524</td>\n",
       "      <td>0.243925</td>\n",
       "      <td>66</td>\n",
       "      <td>0.905797</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.524155</td>\n",
       "      <td>0.269862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.034406</td>\n",
       "      <td>0.038783</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.238250</td>\n",
       "      <td>67</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.314270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.033985</td>\n",
       "      <td>0.037829</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.490476</td>\n",
       "      <td>0.224636</td>\n",
       "      <td>69</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.536643</td>\n",
       "      <td>0.287523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.059563</td>\n",
       "      <td>0.037497</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.242776</td>\n",
       "      <td>55</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.801418</td>\n",
       "      <td>0.661939</td>\n",
       "      <td>0.233241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.070369</td>\n",
       "      <td>0.024599</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.075170</td>\n",
       "      <td>6</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.980831</td>\n",
       "      <td>0.012407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.061088</td>\n",
       "      <td>0.036350</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.258240</td>\n",
       "      <td>47</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.751516</td>\n",
       "      <td>0.295711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.045143</td>\n",
       "      <td>0.028196</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>relu</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.277125</td>\n",
       "      <td>43</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.907801</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.737383</td>\n",
       "      <td>0.286869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.049885</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>relu</td>\n",
       "      <td>(7,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>39</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.877120</td>\n",
       "      <td>0.143806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.027544</td>\n",
       "      <td>0.032807</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.204215</td>\n",
       "      <td>74</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.520095</td>\n",
       "      <td>0.264120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.024087</td>\n",
       "      <td>0.027217</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.197408</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.527187</td>\n",
       "      <td>0.274150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.028927</td>\n",
       "      <td>0.033614</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.197408</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.527187</td>\n",
       "      <td>0.274150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.028115</td>\n",
       "      <td>0.033275</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.538095</td>\n",
       "      <td>0.283480</td>\n",
       "      <td>61</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.259614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.064091</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>23</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.921986</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.925737</td>\n",
       "      <td>0.053379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.027491</td>\n",
       "      <td>0.031803</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.197408</td>\n",
       "      <td>76</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.527187</td>\n",
       "      <td>0.274150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.058697</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>relu</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.054749</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985713</td>\n",
       "      <td>0.011582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.058315</td>\n",
       "      <td>0.014197</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>relu</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.038903</td>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995272</td>\n",
       "      <td>0.006687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.030161</td>\n",
       "      <td>0.036703</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.490476</td>\n",
       "      <td>0.224636</td>\n",
       "      <td>69</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.491726</td>\n",
       "      <td>0.224001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>relu</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.028938</td>\n",
       "      <td>0.035078</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.480952</td>\n",
       "      <td>0.211022</td>\n",
       "      <td>71</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.310926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.035423</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>relu</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.480952</td>\n",
       "      <td>0.211022</td>\n",
       "      <td>71</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.508274</td>\n",
       "      <td>0.247404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.026490</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.303258</td>\n",
       "      <td>60</td>\n",
       "      <td>0.905797</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.524155</td>\n",
       "      <td>0.269862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.070866</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>relu</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.058879</td>\n",
       "      <td>28</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906876</td>\n",
       "      <td>0.066280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.053739</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>relu</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.230704</td>\n",
       "      <td>58</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.624113</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.601758</td>\n",
       "      <td>0.210635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.049586</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>relu</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.223625</td>\n",
       "      <td>56</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.725152</td>\n",
       "      <td>0.277135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.078909</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>relu</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.096530</td>\n",
       "      <td>21</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.959657</td>\n",
       "      <td>0.017527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.052574</td>\n",
       "      <td>0.033673</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>relu</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>0.290388</td>\n",
       "      <td>41</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.746891</td>\n",
       "      <td>0.293118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.067127      0.023680         0.000867        0.000066   \n",
       "1        0.058989      0.000247         0.000831        0.000008   \n",
       "2        0.051481      0.017373         0.000855        0.000068   \n",
       "3        0.048233      0.016283         0.000800        0.000015   \n",
       "4        0.057886      0.014541         0.000831        0.000010   \n",
       "5        0.067743      0.005989         0.000844        0.000017   \n",
       "6        0.080654      0.009721         0.000882        0.000041   \n",
       "7        0.073303      0.003854         0.001056        0.000276   \n",
       "8        0.072371      0.003193         0.000842        0.000005   \n",
       "9        0.061050      0.012812         0.000860        0.000029   \n",
       "10       0.061105      0.001411         0.000806        0.000015   \n",
       "11       0.054143      0.010299         0.000800        0.000013   \n",
       "12       0.076107      0.002274         0.000987        0.000187   \n",
       "13       0.073388      0.000108         0.000808        0.000011   \n",
       "14       0.071367      0.000450         0.000851        0.000028   \n",
       "15       0.071353      0.000087         0.000802        0.000010   \n",
       "16       0.070807      0.001054         0.000812        0.000020   \n",
       "17       0.070942      0.000266         0.000825        0.000030   \n",
       "18       0.068196      0.004319         0.000816        0.000033   \n",
       "19       0.070639      0.000360         0.000818        0.000005   \n",
       "20       0.071261      0.000238         0.000815        0.000023   \n",
       "21       0.073574      0.002803         0.000837        0.000021   \n",
       "22       0.041393      0.026982         0.000766        0.000025   \n",
       "23       0.004731      0.000962         0.000746        0.000015   \n",
       "24       0.056559      0.014107         0.000802        0.000024   \n",
       "25       0.063974      0.005955         0.000828        0.000012   \n",
       "26       0.030395      0.035163         0.000807        0.000035   \n",
       "27       0.029712      0.036393         0.000793        0.000018   \n",
       "28       0.031180      0.033444         0.000786        0.000022   \n",
       "29       0.069245      0.008611         0.000856        0.000012   \n",
       "..            ...           ...              ...             ...   \n",
       "58       0.005325      0.001198         0.000783        0.000006   \n",
       "59       0.060108      0.039002         0.000828        0.000025   \n",
       "60       0.032669      0.037862         0.000818        0.000039   \n",
       "61       0.034406      0.038783         0.000827        0.000044   \n",
       "62       0.033985      0.037829         0.000819        0.000032   \n",
       "63       0.059563      0.037497         0.000823        0.000022   \n",
       "64       0.070369      0.024599         0.000822        0.000012   \n",
       "65       0.061088      0.036350         0.000838        0.000029   \n",
       "66       0.003851      0.000330         0.000749        0.000009   \n",
       "67       0.003885      0.000348         0.000740        0.000010   \n",
       "68       0.045143      0.028196         0.000798        0.000035   \n",
       "69       0.049885      0.012048         0.000862        0.000018   \n",
       "70       0.027544      0.032807         0.000791        0.000023   \n",
       "71       0.024087      0.027217         0.000793        0.000020   \n",
       "72       0.028927      0.033614         0.000794        0.000021   \n",
       "73       0.028115      0.033275         0.000790        0.000013   \n",
       "74       0.064091      0.018651         0.000852        0.000044   \n",
       "75       0.027491      0.031803         0.000825        0.000038   \n",
       "76       0.058697      0.012225         0.000828        0.000032   \n",
       "77       0.058315      0.014197         0.000859        0.000011   \n",
       "78       0.030161      0.036703         0.000795        0.000020   \n",
       "79       0.004346      0.000320         0.000779        0.000004   \n",
       "80       0.028938      0.035078         0.000796        0.000028   \n",
       "81       0.030529      0.035423         0.000813        0.000026   \n",
       "82       0.026490      0.029870         0.000791        0.000022   \n",
       "83       0.070866      0.012502         0.000836        0.000006   \n",
       "84       0.053739      0.034594         0.000841        0.000029   \n",
       "85       0.049586      0.031893         0.000834        0.000042   \n",
       "86       0.078909      0.000948         0.000818        0.000010   \n",
       "87       0.052574      0.033673         0.000825        0.000028   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "0          identity                     (1,)                     0.01   \n",
       "1          identity                     (1,)                     0.05   \n",
       "2          identity                     (7,)                     0.01   \n",
       "3          identity                     (7,)                     0.05   \n",
       "4          identity                   (1, 6)                     0.01   \n",
       "5          identity                   (1, 6)                     0.05   \n",
       "6          identity                   (2, 5)                     0.01   \n",
       "7          identity                   (2, 5)                     0.05   \n",
       "8          identity                   (3, 4)                     0.01   \n",
       "9          identity                   (3, 4)                     0.05   \n",
       "10         identity                    (11,)                     0.01   \n",
       "11         identity                    (11,)                     0.05   \n",
       "12         identity                  (1, 10)                     0.01   \n",
       "13         identity                  (1, 10)                     0.05   \n",
       "14         identity                   (2, 9)                     0.01   \n",
       "15         identity                   (2, 9)                     0.05   \n",
       "16         identity                   (3, 8)                     0.01   \n",
       "17         identity                   (3, 8)                     0.05   \n",
       "18         identity                   (4, 7)                     0.01   \n",
       "19         identity                   (4, 7)                     0.05   \n",
       "20         identity                   (5, 6)                     0.01   \n",
       "21         identity                   (5, 6)                     0.05   \n",
       "22         logistic                     (1,)                     0.01   \n",
       "23         logistic                     (1,)                     0.05   \n",
       "24         logistic                     (7,)                     0.01   \n",
       "25         logistic                     (7,)                     0.05   \n",
       "26         logistic                   (1, 6)                     0.01   \n",
       "27         logistic                   (1, 6)                     0.05   \n",
       "28         logistic                   (2, 5)                     0.01   \n",
       "29         logistic                   (2, 5)                     0.05   \n",
       "..              ...                      ...                      ...   \n",
       "58             tanh                   (2, 9)                     0.01   \n",
       "59             tanh                   (2, 9)                     0.05   \n",
       "60             tanh                   (3, 8)                     0.01   \n",
       "61             tanh                   (3, 8)                     0.05   \n",
       "62             tanh                   (4, 7)                     0.01   \n",
       "63             tanh                   (4, 7)                     0.05   \n",
       "64             tanh                   (5, 6)                     0.01   \n",
       "65             tanh                   (5, 6)                     0.05   \n",
       "66             relu                     (1,)                     0.01   \n",
       "67             relu                     (1,)                     0.05   \n",
       "68             relu                     (7,)                     0.01   \n",
       "69             relu                     (7,)                     0.05   \n",
       "70             relu                   (1, 6)                     0.01   \n",
       "71             relu                   (1, 6)                     0.05   \n",
       "72             relu                   (2, 5)                     0.01   \n",
       "73             relu                   (2, 5)                     0.05   \n",
       "74             relu                   (3, 4)                     0.01   \n",
       "75             relu                   (3, 4)                     0.05   \n",
       "76             relu                    (11,)                     0.01   \n",
       "77             relu                    (11,)                     0.05   \n",
       "78             relu                  (1, 10)                     0.01   \n",
       "79             relu                  (1, 10)                     0.05   \n",
       "80             relu                   (2, 9)                     0.01   \n",
       "81             relu                   (2, 9)                     0.05   \n",
       "82             relu                   (3, 8)                     0.01   \n",
       "83             relu                   (3, 8)                     0.05   \n",
       "84             relu                   (4, 7)                     0.01   \n",
       "85             relu                   (4, 7)                     0.05   \n",
       "86             relu                   (5, 6)                     0.01   \n",
       "87             relu                   (5, 6)                     0.05   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'activation': 'identity', 'hidden_layer_sizes...           0.888889   \n",
       "1   {'activation': 'identity', 'hidden_layer_sizes...           0.888889   \n",
       "2   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "3   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "4   {'activation': 'identity', 'hidden_layer_sizes...           0.875000   \n",
       "5   {'activation': 'identity', 'hidden_layer_sizes...           0.888889   \n",
       "6   {'activation': 'identity', 'hidden_layer_sizes...           0.930556   \n",
       "7   {'activation': 'identity', 'hidden_layer_sizes...           0.916667   \n",
       "8   {'activation': 'identity', 'hidden_layer_sizes...           0.986111   \n",
       "9   {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "10  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "11  {'activation': 'identity', 'hidden_layer_sizes...           0.986111   \n",
       "12  {'activation': 'identity', 'hidden_layer_sizes...           0.861111   \n",
       "13  {'activation': 'identity', 'hidden_layer_sizes...           0.861111   \n",
       "14  {'activation': 'identity', 'hidden_layer_sizes...           0.944444   \n",
       "15  {'activation': 'identity', 'hidden_layer_sizes...           0.986111   \n",
       "16  {'activation': 'identity', 'hidden_layer_sizes...           0.958333   \n",
       "17  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "18  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "19  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "20  {'activation': 'identity', 'hidden_layer_sizes...           0.972222   \n",
       "21  {'activation': 'identity', 'hidden_layer_sizes...           0.986111   \n",
       "22  {'activation': 'logistic', 'hidden_layer_sizes...           0.277778   \n",
       "23  {'activation': 'logistic', 'hidden_layer_sizes...           0.277778   \n",
       "24  {'activation': 'logistic', 'hidden_layer_sizes...           0.875000   \n",
       "25  {'activation': 'logistic', 'hidden_layer_sizes...           0.972222   \n",
       "26  {'activation': 'logistic', 'hidden_layer_sizes...           0.638889   \n",
       "27  {'activation': 'logistic', 'hidden_layer_sizes...           0.861111   \n",
       "28  {'activation': 'logistic', 'hidden_layer_sizes...           0.333333   \n",
       "29  {'activation': 'logistic', 'hidden_layer_sizes...           0.861111   \n",
       "..                                                ...                ...   \n",
       "58  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "59  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.847222   \n",
       "60  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.847222   \n",
       "61  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "62  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "63  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.333333   \n",
       "64  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.972222   \n",
       "65  {'activation': 'tanh', 'hidden_layer_sizes': (...           0.958333   \n",
       "66  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "67  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "68  {'activation': 'relu', 'hidden_layer_sizes': (...           0.944444   \n",
       "69  {'activation': 'relu', 'hidden_layer_sizes': (...           0.694444   \n",
       "70  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "71  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "72  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "73  {'activation': 'relu', 'hidden_layer_sizes': (...           0.930556   \n",
       "74  {'activation': 'relu', 'hidden_layer_sizes': (...           0.888889   \n",
       "75  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "76  {'activation': 'relu', 'hidden_layer_sizes': (...           0.972222   \n",
       "77  {'activation': 'relu', 'hidden_layer_sizes': (...           0.930556   \n",
       "78  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "79  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "80  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "81  {'activation': 'relu', 'hidden_layer_sizes': (...           0.333333   \n",
       "82  {'activation': 'relu', 'hidden_layer_sizes': (...           0.972222   \n",
       "83  {'activation': 'relu', 'hidden_layer_sizes': (...           0.861111   \n",
       "84  {'activation': 'relu', 'hidden_layer_sizes': (...           0.888889   \n",
       "85  {'activation': 'relu', 'hidden_layer_sizes': (...           0.861111   \n",
       "86  {'activation': 'relu', 'hidden_layer_sizes': (...           0.972222   \n",
       "87  {'activation': 'relu', 'hidden_layer_sizes': (...           0.972222   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.913043           0.753623         0.852381        0.069790   \n",
       "1            0.913043           0.753623         0.852381        0.069790   \n",
       "2            0.971014           0.797101         0.914286        0.081977   \n",
       "3            0.956522           0.840580         0.923810        0.058577   \n",
       "4            0.913043           0.753623         0.847619        0.067576   \n",
       "5            0.942029           0.797101         0.876190        0.059454   \n",
       "6            0.942029           0.811594         0.895238        0.058701   \n",
       "7            0.956522           0.782609         0.885714        0.073951   \n",
       "8            0.956522           0.797101         0.914286        0.082867   \n",
       "9            0.971014           0.826087         0.923810        0.068363   \n",
       "10           0.985507           0.797101         0.919048        0.085480   \n",
       "11           0.942029           0.840580         0.923810        0.060959   \n",
       "12           0.942029           0.753623         0.852381        0.076625   \n",
       "13           0.942029           0.753623         0.852381        0.076625   \n",
       "14           0.971014           0.782609         0.900000        0.082838   \n",
       "15           0.913043           0.739130         0.880952        0.103627   \n",
       "16           0.956522           0.811594         0.909524        0.068510   \n",
       "17           0.956522           0.782609         0.904762        0.085693   \n",
       "18           0.985507           0.753623         0.904762        0.105868   \n",
       "19           0.971014           0.782609         0.909524        0.088784   \n",
       "20           0.971014           0.811594         0.919048        0.075170   \n",
       "21           0.971014           0.840580         0.933333        0.065179   \n",
       "22           0.913043           0.826087         0.666667        0.283103   \n",
       "23           0.333333           0.333333         0.314286        0.026370   \n",
       "24           0.637681           0.768116         0.761905        0.097305   \n",
       "25           0.927536           0.782609         0.895238        0.080887   \n",
       "26           0.333333           0.333333         0.438095        0.145036   \n",
       "27           0.405797           0.333333         0.538095        0.235161   \n",
       "28           0.333333           0.753623         0.471429        0.197408   \n",
       "29           0.623188           0.623188         0.704762        0.112933   \n",
       "..                ...                ...              ...             ...   \n",
       "58           0.333333           0.333333         0.333333        0.000000   \n",
       "59           0.333333           0.797101         0.661905        0.230765   \n",
       "60           0.333333           0.333333         0.509524        0.243925   \n",
       "61           0.333333           0.840580         0.500000        0.238250   \n",
       "62           0.333333           0.811594         0.490476        0.224636   \n",
       "63           0.913043           0.724638         0.652381        0.242776   \n",
       "64           0.971014           0.811594         0.919048        0.075170   \n",
       "65           0.333333           0.724638         0.676190        0.258240   \n",
       "66           0.333333           0.333333         0.333333        0.000000   \n",
       "67           0.333333           0.333333         0.333333        0.000000   \n",
       "68           0.898551           0.333333         0.728571        0.277125   \n",
       "69           0.898551           0.724638         0.771429        0.089783   \n",
       "70           0.333333           0.768116         0.476190        0.204215   \n",
       "71           0.333333           0.753623         0.471429        0.197408   \n",
       "72           0.333333           0.753623         0.471429        0.197408   \n",
       "73           0.333333           0.333333         0.538095        0.283480   \n",
       "74           0.913043           0.855072         0.885714        0.023609   \n",
       "75           0.333333           0.753623         0.471429        0.197408   \n",
       "76           0.971014           0.855072         0.933333        0.054749   \n",
       "77           0.913043           0.840580         0.895238        0.038903   \n",
       "78           0.811594           0.333333         0.490476        0.224636   \n",
       "79           0.333333           0.333333         0.333333        0.000000   \n",
       "80           0.333333           0.782609         0.480952        0.211022   \n",
       "81           0.782609           0.333333         0.480952        0.211022   \n",
       "82           0.333333           0.333333         0.552381        0.303258   \n",
       "83           0.942029           0.797101         0.866667        0.058879   \n",
       "84           0.536232           0.333333         0.590476        0.230704   \n",
       "85           0.333333           0.724638         0.642857        0.223625   \n",
       "86           0.942029           0.753623         0.890476        0.096530   \n",
       "87           0.927536           0.333333         0.747619        0.290388   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                30            0.840580            0.858156   \n",
       "1                30            0.891304            0.851064   \n",
       "2                 9            0.985507            0.964539   \n",
       "3                 3            0.978261            0.964539   \n",
       "4                34            0.869565            0.851064   \n",
       "5                26            0.862319            0.858156   \n",
       "6                18            0.927536            0.879433   \n",
       "7                23            0.927536            0.964539   \n",
       "8                 9            0.985507            0.964539   \n",
       "9                 3            0.985507            0.971631   \n",
       "10                6            0.978261            0.964539   \n",
       "11                3            0.985507            0.971631   \n",
       "12               30            0.891304            0.851064   \n",
       "13               30            0.884058            0.858156   \n",
       "14               17            0.985507            0.971631   \n",
       "15               25            0.971014            0.971631   \n",
       "16               11            0.971014            0.964539   \n",
       "17               14            0.971014            0.957447   \n",
       "18               14            0.971014            0.957447   \n",
       "19               11            0.978261            0.964539   \n",
       "20                6            0.978261            0.964539   \n",
       "21                1            0.985507            0.971631   \n",
       "22               50            0.282609            0.872340   \n",
       "23               88            0.239130            0.333333   \n",
       "24               40            0.891304            0.687943   \n",
       "25               18            0.985507            0.978723   \n",
       "26               80            0.644928            0.333333   \n",
       "27               61            0.876812            0.418440   \n",
       "28               76            0.333333            0.333333   \n",
       "29               45            0.891304            0.602837   \n",
       "..              ...                 ...                 ...   \n",
       "58               81            0.333333            0.333333   \n",
       "59               52            0.898551            0.333333   \n",
       "60               66            0.905797            0.333333   \n",
       "61               67            0.333333            0.333333   \n",
       "62               69            0.333333            0.333333   \n",
       "63               55            0.333333            0.851064   \n",
       "64                6            0.963768            0.985816   \n",
       "65               47            0.963768            0.333333   \n",
       "66               81            0.333333            0.333333   \n",
       "67               81            0.333333            0.333333   \n",
       "68               43            0.971014            0.907801   \n",
       "69               39            0.673913            0.971631   \n",
       "70               74            0.333333            0.333333   \n",
       "71               76            0.333333            0.333333   \n",
       "72               76            0.333333            0.333333   \n",
       "73               61            0.884058            0.333333   \n",
       "74               23            0.862319            0.921986   \n",
       "75               76            0.333333            0.333333   \n",
       "76                1            0.985507            0.971631   \n",
       "77               18            1.000000            0.985816   \n",
       "78               69            0.333333            0.808511   \n",
       "79               81            0.333333            0.333333   \n",
       "80               71            0.333333            0.333333   \n",
       "81               71            0.333333            0.858156   \n",
       "82               60            0.905797            0.333333   \n",
       "83               28            0.869565            0.851064   \n",
       "84               58            0.847826            0.624113   \n",
       "85               56            0.913043            0.333333   \n",
       "86               21            0.978261            0.964539   \n",
       "87               41            0.978261            0.929078   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.914894          0.871210         0.031712  \n",
       "1             0.914894          0.885754         0.026352  \n",
       "2             1.000000          0.983349         0.014557  \n",
       "3             1.000000          0.980933         0.014600  \n",
       "4             0.914894          0.878508         0.026815  \n",
       "5             0.929078          0.883184         0.032496  \n",
       "6             1.000000          0.935656         0.049555  \n",
       "7             1.000000          0.964025         0.029585  \n",
       "8             0.992908          0.980985         0.012015  \n",
       "9             1.000000          0.985713         0.011582  \n",
       "10            1.000000          0.980933         0.014600  \n",
       "11            1.000000          0.985713         0.011582  \n",
       "12            0.914894          0.885754         0.026352  \n",
       "13            0.914894          0.885703         0.023192  \n",
       "14            1.000000          0.985713         0.011582  \n",
       "15            0.992908          0.978518         0.010178  \n",
       "16            1.000000          0.978518         0.015419  \n",
       "17            0.992908          0.973790         0.014609  \n",
       "18            1.000000          0.976154         0.017748  \n",
       "19            1.000000          0.980933         0.014600  \n",
       "20            1.000000          0.980933         0.014600  \n",
       "21            1.000000          0.985713         0.011582  \n",
       "22            0.929078          0.694676         0.292295  \n",
       "23            0.333333          0.301932         0.044408  \n",
       "24            1.000000          0.859749         0.129336  \n",
       "25            0.992908          0.985713         0.005793  \n",
       "26            0.262411          0.413557         0.166146  \n",
       "27            0.333333          0.542862         0.238681  \n",
       "28            0.900709          0.522459         0.267464  \n",
       "29            0.645390          0.713177         0.127147  \n",
       "..                 ...               ...              ...  \n",
       "58            0.333333          0.333333         0.000000  \n",
       "59            0.943262          0.725049         0.277585  \n",
       "60            0.333333          0.524155         0.269862  \n",
       "61            1.000000          0.555556         0.314270  \n",
       "62            0.943262          0.536643         0.287523  \n",
       "63            0.801418          0.661939         0.233241  \n",
       "64            0.992908          0.980831         0.012407  \n",
       "65            0.957447          0.751516         0.295711  \n",
       "66            0.333333          0.333333         0.000000  \n",
       "67            0.333333          0.333333         0.000000  \n",
       "68            0.333333          0.737383         0.286869  \n",
       "69            0.985816          0.877120         0.143806  \n",
       "70            0.893617          0.520095         0.264120  \n",
       "71            0.914894          0.527187         0.274150  \n",
       "72            0.914894          0.527187         0.274150  \n",
       "73            0.333333          0.516908         0.259614  \n",
       "74            0.992908          0.925737         0.053379  \n",
       "75            0.914894          0.527187         0.274150  \n",
       "76            1.000000          0.985713         0.011582  \n",
       "77            1.000000          0.995272         0.006687  \n",
       "78            0.333333          0.491726         0.224001  \n",
       "79            0.333333          0.333333         0.000000  \n",
       "80            0.992908          0.553191         0.310926  \n",
       "81            0.333333          0.508274         0.247404  \n",
       "82            0.333333          0.524155         0.269862  \n",
       "83            1.000000          0.906876         0.066280  \n",
       "84            0.333333          0.601758         0.210635  \n",
       "85            0.929078          0.725152         0.277135  \n",
       "86            0.936170          0.959657         0.017527  \n",
       "87            0.333333          0.746891         0.293118  \n",
       "\n",
       "[88 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas do modelo que o obteve a melhor média de acurácia entre os folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor média de acurácia entre os folds = 0.9952718676122932\n"
     ]
    }
   ],
   "source": [
    "print(\"Melhor média de acurácia entre os folds = \" + str(max(results['mean_train_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.058315</td>\n",
       "      <td>0.014197</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>relu</td>\n",
       "      <td>(11,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.84058</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.038903</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995272</td>\n",
       "      <td>0.006687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "77       0.058315      0.014197         0.000859        0.000011   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "77             relu                    (11,)                     0.05   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "77  {'activation': 'relu', 'hidden_layer_sizes': (...           0.930556   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "77           0.913043            0.84058         0.895238        0.038903   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "77               18                 1.0            0.985816   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "77                 1.0          0.995272         0.006687  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results['mean_train_score']==max(results['mean_train_score'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características do melhor modelo que endereça a tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 6), learning_rate='constant',\n",
       "       learning_rate_init=0.05, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos trabalhando com pouco dados, escolhemos o solver 'LBFGS'.  \n",
    "Convergindo mais rápido e trabalhando com pouca memŕia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
